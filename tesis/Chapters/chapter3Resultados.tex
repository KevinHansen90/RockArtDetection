%======================================================================
\chapter{Resultados}\label{ch:resultados}
%======================================================================

\section{Estructura general}
En este capítulo se presentan los hallazgos cuantitativos y cualitativos obtenidos a partir de los dos experimentos principales:

\begin{enumerate}
  \item \textbf{Detección Supervisada de Motivos}
  \item \textbf{Agrupamiento No Supervisado de Motivos}
\end{enumerate}

Cada bloque de resultados conserva la lógica de las fases descritas en el capítulo de Materiales y Métodos para facilitar la lectura cruzada.

%----------------------------------------------------------------------
\section{Detección Supervisada de Motivos}

\subsection{Fase 1 — Pilotaje inicial}
\begin{itemize}
  \item Tabla con la evolución de \texttt{train\_loss}, \texttt{val\_loss}, mAP$_{0.5}$ y mAR$_{100}$ (una fila por época y modelo).
  \item Gráficas de las curvas de pérdida y métricas para las cuatro arquitecturas.
  \item Discusión breve: estabilidad de la convergencia, sobre–ajuste detectado, sensibilidad a la LR.
\end{itemize}

\subsection{Fase 2 — Comparación de Preprocesamientos}
\begin{itemize}
  \item Tabla resumen (\textit{modelo} × \textit{preproc}) con el mejor mAP$_{0.5}$ alcanzado.
  \item Box plots o violin plots que muestren la dispersión por técnica.
  \item Breve análisis de qué filtros benefician más a cada arquitectura y por qué.
\end{itemize}

\subsection{Fase 3 — Selección de Configuraciones Óptimas}
\begin{itemize}
  \item Ranking de las tres combinaciones elegidas (modelo + preproc) con sus métricas finales.
  \item Justificación de la elección basándose en el equilibrio precisión/recuperación.
\end{itemize}

\subsection{Fase 4 — Entrenamiento Integral}
\begin{itemize}
  \item Tabla con mAP$_{0.5}$ y mAR$_{100}$ promedios por conjunto (\textit{train}, \textit{val}, \textit{test}).
  \item Ejemplos cualitativos: figuras etiquetadas correctamente vs.\ errores típicos.
\end{itemize}

\subsection{Fase 5 — Validación Experta}
\begin{itemize}
  \item Tabla de observaciones de la arqueóloga: aciertos, falsos positivos, falsos negativos.
  \item Comentarios sobre superposiciones críticas, bajo contraste y erosión.
  \item Conclusiones preliminares sobre utilidad del modelo en trabajo de campo.
\end{itemize}

%----------------------------------------------------------------------
\section{Agrupamiento No Supervisado de Motivos}

\subsection{Calidad Interna de Clusters}
\begin{itemize}
  \item Tabla con Silhouette, Davies–Bouldin y Calinski–Harabasz normalizados para las 16 combinaciones \textit{extractor} × \textit{algoritmo}.
  \item Gráfica \textit{elbow} (K–Means, Agglomerative y Spectral) mostrando la variación de los índices entre $k=2$ y $k=10$.
  \item Discusión sobre el número óptimo de clusters sugerido por cada métrica.
\end{itemize}

\subsection{Comparación con Clasificación Arqueológica}
\begin{itemize}
  \item Matriz de confusión entre clusters y las 6 categorías zoomórficas manuales.
  \item Métricas de homogeneidad y completitud para las tres configuraciones mejor puntuadas.
  \item Ejemplos visuales (collages) de clusters “puros” vs.\ mezclados.
\end{itemize}

\subsection{Síntesis de Resultados No Supervisados}
\begin{itemize}
  \item Resumen de qué configuraciones agrupan mejor motivos similares.
  \item Comentarios de la arqueóloga sobre la coherencia semántica de los conglomerados.
\end{itemize}

%----------------------------------------------------------------------
\section{Comparación Cruzada y Costes Computacionales}

\begin{itemize}
  \item Tabla de tiempo de entrenamiento/inferencia y uso de VRAM por modelo.
  \item Discusión sobre la relación coste–beneficio entre arquitecturas y técnicas de preprocesamiento.
  \item Implicaciones para la adopción práctica en proyectos arqueológicos.
\end{itemize}
