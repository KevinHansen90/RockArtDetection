\chapter{Resultados}\label{ch:resultados}

\section{Estructura general}
En este capítulo se presentan los hallazgos cuantitativos y cualitativos obtenidos a partir de los dos experimentos principales:

\begin{enumerate}
  \item \textbf{Detección Supervisada de Motivos}
  \item \textbf{Agrupamiento No Supervisado de Motivos}
\end{enumerate}

Cada bloque de resultados conserva la lógica de las fases descritas en el capítulo de Materiales y Métodos para facilitar la lectura cruzada.

%----------------------------------------------------------------------
\section{Detección Supervisada de Motivos}

\subsection{Fase 1 — Pilotaje inicial}
\begin{itemize}
  \item Tabla con la evolución de \texttt{train\_loss}, \texttt{val\_loss}, mAP$_{0.5}$ y mAR$_{100}$ (una fila por época y modelo).
  \item Gráficas de las curvas de pérdida y métricas para las cuatro arquitecturas.
  \item Discusión breve: estabilidad de la convergencia, sobre–ajuste detectado, sensibilidad a la LR.
\end{itemize}

\subsection{Fase 2 — Comparación de Preprocesamientos}
\begin{itemize}
  \item Tabla resumen (\textit{modelo} × \textit{preproc}) con el mejor mAP$_{0.5}$ alcanzado.
  \item Box plots o violin plots que muestren la dispersión por técnica.
  \item Breve análisis de qué filtros benefician más a cada arquitectura y por qué.
\end{itemize}

\subsection{Fase 3 — Selección de Configuraciones Óptimas}
\begin{itemize}
  \item Ranking de las tres combinaciones elegidas (modelo + preproc) con sus métricas finales.
  \item Justificación de la elección basándose en el equilibrio precisión/recuperación.
\end{itemize}

\subsection{Fase 4 — Entrenamiento Integral}
\begin{itemize}
  \item Tabla con mAP$_{0.5}$ y mAR$_{100}$ promedios por conjunto (\textit{train}, \textit{val}, \textit{test}).
  \item Ejemplos cualitativos: figuras etiquetadas correctamente vs.\ errores típicos.
\end{itemize}

\subsection{Fase 5 — Validación Experta}
\begin{itemize}
  \item Tabla de observaciones de la arqueóloga: aciertos, falsos positivos, falsos negativos.
  \item Comentarios sobre superposiciones críticas, bajo contraste y erosión.
  \item Conclusiones preliminares sobre utilidad del modelo en trabajo de campo.
\end{itemize}

%----------------------------------------------------------------------
\section{Agrupamiento No Supervisado de Motivos}

%--------------------------------------------------------------------
\subsection{Calidad Interna de Clusters}
%--------------------------------------------------------------------

\paragraph{Convención de métricas.}
Para todas las configuraciones se reportan tres índices de cohesión–separación
re-escalados al rango \([0,1]\) y con dirección “mayor–mejor”:
\(\widehat S=(S+1)/2\) para Silhouette,
\(\widehat{DB}=1-\frac{DB-\min(DB)}{\max(DB)-\min(DB)}\) para Davies–Bouldin
(invirtiendo su sentido original) y
\(\widehat{CH}=\frac{CH-\min(CH)}{\max(CH)-\min(CH)}\) para Calinski–Harabasz.
Con esta normalización los tres índices son directamente comparables.

%....................................................................
\subsubsection{Particionales: K–Means, Agglomerative, Spectral}
%....................................................................

La Tabla~\ref{tab:int_quality_partitional} presenta las \(108\) combinaciones \textit{extractor} × \textit{algoritmo} ×~\(k\) correspondientes a métodos particionales con \(k=2\ldots10\).

\begin{longtable}{llrrrr}
\caption{Métricas de calidad interna normalizadas para K–Means, Agglomerative y Spectral clustering ($k=2$–10).}
\label{tab:int_quality_partitional}\\
\hline
\textbf{model} & \textbf{algo} & \textbf{k} & \textbf{silhouette} & \textbf{db\_inv} & \textbf{ch\_norm}\\
\hline
\endfirsthead
\caption[]{Métricas de calidad interna normalizadas para K–Means, Agglomerative y Spectral clustering ($k=2$–10) (cont.).}\\
\hline
\textbf{model} & \textbf{algo} & \textbf{k} & \textbf{silhouette} & \textbf{db\_inv} & \textbf{ch\_norm}\\
\hline
\endhead
\hline
\multicolumn{6}{r}{\small Continúa en la página siguiente}\\
\hline
\endfoot
\hline
\endlastfoot
   resnet18 &        kmeans &  2 &            0.557 &   0.261 &    0.788 \\
   resnet18 &        kmeans &  3 &            0.542 &   0.262 &    0.672 \\
   resnet18 &        kmeans &  4 &            0.541 &   0.289 &    0.526 \\
   resnet18 &        kmeans &  5 &            0.539 &   0.329 &    0.484 \\
   resnet18 &        kmeans &  6 &            0.538 &   0.328 &    0.449 \\
   resnet18 &        kmeans &  7 &            0.538 &   0.344 &    0.416 \\
   resnet18 &        kmeans &  8 &            0.536 &   0.353 &    0.395 \\
   resnet18 &        kmeans &  9 &            0.536 &   0.376 &    0.374 \\
   resnet18 &        kmeans & 10 &            0.539 &   0.408 &    0.358 \\
   resnet18 & agglomerative &  2 &            0.560 &   0.252 &    0.638 \\
   resnet18 & agglomerative &  3 &            0.532 &   0.095 &    0.542 \\
   resnet18 & agglomerative &  4 &            0.523 &   0.080 &    0.426 \\
   resnet18 & agglomerative &  5 &            0.517 &   0.043 &    0.369 \\
   resnet18 & agglomerative &  6 &            0.518 &   0.000 &    0.335 \\
   resnet18 & agglomerative &  7 &            0.520 &   0.079 &    0.311 \\
   resnet18 & agglomerative &  8 &            0.522 &   0.159 &    0.292 \\
   resnet18 & agglomerative &  9 &            0.521 &   0.223 &    0.276 \\
   resnet18 & agglomerative & 10 &            0.517 &   0.191 &    0.263 \\
   resnet18 &      spectral &  2 &            0.546 &   0.149 &    0.683 \\
   resnet18 &      spectral &  3 &            0.536 &   0.385 &    0.420 \\
   resnet18 &      spectral &  4 &            0.509 &   0.481 &    0.283 \\
   resnet18 &      spectral &  5 &            0.505 &   0.522 &    0.217 \\
   resnet18 &      spectral &  6 &            0.503 &   0.485 &    0.209 \\
   resnet18 &      spectral &  7 &            0.513 &   0.434 &    0.265 \\
   resnet18 &      spectral &  8 &            0.513 &   0.477 &    0.257 \\
   resnet18 &      spectral &  9 &            0.515 &   0.463 &    0.263 \\
   resnet18 &      spectral & 10 &            0.513 &   0.439 &    0.238 \\
   resnet50 &        kmeans &  2 &            0.559 &   0.336 &    1.000 \\
   resnet50 &        kmeans &  3 &            0.542 &   0.262 &    0.730 \\
   resnet50 &        kmeans &  4 &            0.546 &   0.335 &    0.652 \\
   resnet50 &        kmeans &  5 &            0.542 &   0.347 &    0.578 \\
   resnet50 &        kmeans &  6 &            0.542 &   0.338 &    0.521 \\
   resnet50 &        kmeans &  7 &            0.543 &   0.359 &    0.470 \\
   resnet50 &        kmeans &  8 &            0.541 &   0.296 &    0.434 \\
   resnet50 &        kmeans &  9 &            0.541 &   0.337 &    0.407 \\
   resnet50 &        kmeans & 10 &            0.541 &   0.359 &    0.380 \\
   resnet50 & agglomerative &  2 &            0.548 &   0.187 &    0.721 \\
   resnet50 & agglomerative &  3 &            0.533 &   0.194 &    0.538 \\
   resnet50 & agglomerative &  4 &            0.533 &   0.223 &    0.463 \\
   resnet50 & agglomerative &  5 &            0.529 &   0.182 &    0.430 \\
   resnet50 & agglomerative &  6 &            0.527 &   0.129 &    0.383 \\
   resnet50 & agglomerative &  7 &            0.526 &   0.158 &    0.347 \\
   resnet50 & agglomerative &  8 &            0.526 &   0.205 &    0.321 \\
   resnet50 & agglomerative &  9 &            0.516 &   0.189 &    0.302 \\
   resnet50 & agglomerative & 10 &            0.514 &   0.222 &    0.287 \\
   resnet50 &      spectral &  2 &            0.544 &   0.207 &    0.712 \\
   resnet50 &      spectral &  3 &            0.532 &   0.315 &    0.555 \\
   resnet50 &      spectral &  4 &            0.530 &   0.287 &    0.391 \\
   resnet50 &      spectral &  5 &            0.526 &   0.447 &    0.326 \\
   resnet50 &      spectral &  6 &            0.524 &   0.449 &    0.303 \\
   resnet50 &      spectral &  7 &            0.524 &   0.364 &    0.272 \\
   resnet50 &      spectral &  8 &            0.527 &   0.428 &    0.300 \\
   resnet50 &      spectral &  9 &            0.524 &   0.398 &    0.259 \\
   resnet50 &      spectral & 10 &            0.517 &   0.488 &    0.232 \\
densenet121 &        kmeans &  2 &            0.553 &   0.303 &    0.905 \\
densenet121 &        kmeans &  3 &            0.545 &   0.271 &    0.728 \\
densenet121 &        kmeans &  4 &            0.548 &   0.388 &    0.666 \\
densenet121 &        kmeans &  5 &            0.543 &   0.371 &    0.582 \\
densenet121 &        kmeans &  6 &            0.544 &   0.393 &    0.532 \\
densenet121 &        kmeans &  7 &            0.543 &   0.343 &    0.470 \\
densenet121 &        kmeans &  8 &            0.543 &   0.392 &    0.458 \\
densenet121 &        kmeans &  9 &            0.536 &   0.351 &    0.419 \\
densenet121 &        kmeans & 10 &            0.537 &   0.335 &    0.391 \\
densenet121 & agglomerative &  2 &            0.544 &   0.242 &    0.739 \\
densenet121 & agglomerative &  3 &            0.543 &   0.279 &    0.571 \\
densenet121 & agglomerative &  4 &            0.537 &   0.160 &    0.493 \\
densenet121 & agglomerative &  5 &            0.528 &   0.203 &    0.445 \\
densenet121 & agglomerative &  6 &            0.526 &   0.178 &    0.400 \\
densenet121 & agglomerative &  7 &            0.521 &   0.183 &    0.369 \\
densenet121 & agglomerative &  8 &            0.520 &   0.182 &    0.343 \\
densenet121 & agglomerative &  9 &            0.521 &   0.216 &    0.317 \\
densenet121 & agglomerative & 10 &            0.522 &   0.210 &    0.296 \\
densenet121 &      spectral &  2 &            0.549 &   0.297 &    0.819 \\
densenet121 &      spectral &  3 &            0.535 &   0.449 &    0.419 \\
densenet121 &      spectral &  4 &            0.534 &   0.389 &    0.302 \\
densenet121 &      spectral &  5 &            0.527 &   0.531 &    0.273 \\
densenet121 &      spectral &  6 &            0.523 &   0.472 &    0.274 \\
densenet121 &      spectral &  7 &            0.524 &   0.436 &    0.293 \\
densenet121 &      spectral &  8 &            0.528 &   0.444 &    0.306 \\
densenet121 &      spectral &  9 &            0.524 &   0.427 &    0.270 \\
densenet121 &      spectral & 10 &            0.522 &   0.443 &    0.254 \\
      vgg16 &        kmeans &  2 &            0.559 &   0.343 &    0.990 \\
      vgg16 &        kmeans &  3 &            0.555 &   0.333 &    0.815 \\
      vgg16 &        kmeans &  4 &            0.553 &   0.314 &    0.659 \\
      vgg16 &        kmeans &  5 &            0.543 &   0.292 &    0.587 \\
      vgg16 &        kmeans &  6 &            0.543 &   0.307 &    0.531 \\
      vgg16 &        kmeans &  7 &            0.543 &   0.326 &    0.484 \\
      vgg16 &        kmeans &  8 &            0.541 &   0.346 &    0.450 \\
      vgg16 &        kmeans &  9 &            0.538 &   0.290 &    0.409 \\
      vgg16 &        kmeans & 10 &            0.536 &   0.315 &    0.378 \\
      vgg16 & agglomerative &  2 &            0.552 &   0.287 &    0.870 \\
      vgg16 & agglomerative &  3 &            0.542 &   0.082 &    0.617 \\
      vgg16 & agglomerative &  4 &            0.543 &   0.192 &    0.510 \\
      vgg16 & agglomerative &  5 &            0.526 &   0.171 &    0.442 \\
      vgg16 & agglomerative &  6 &            0.527 &   0.203 &    0.403 \\
      vgg16 & agglomerative &  7 &            0.524 &   0.149 &    0.367 \\
      vgg16 & agglomerative &  8 &            0.520 &   0.121 &    0.338 \\
      vgg16 & agglomerative &  9 &            0.521 &   0.135 &    0.314 \\
      vgg16 & agglomerative & 10 &            0.521 &   0.104 &    0.294 \\
      vgg16 &      spectral &  2 &            0.556 &   0.334 &    0.951 \\
      vgg16 &      spectral &  3 &            0.551 &   0.421 &    0.521 \\
      vgg16 &      spectral &  4 &            0.524 &   0.534 &    0.361 \\
      vgg16 &      spectral &  5 &            0.531 &   0.490 &    0.417 \\
      vgg16 &      spectral &  6 &            0.529 &   0.432 &    0.394 \\
      vgg16 &      spectral &  7 &            0.528 &   0.389 &    0.336 \\
      vgg16 &      spectral &  8 &            0.527 &   0.381 &    0.329 \\
      vgg16 &      spectral &  9 &            0.530 &   0.393 &    0.321 \\
      vgg16 &      spectral & 10 &            0.529 &   0.436 &    0.287 \\
\end{longtable}

Se observa que:

\begin{itemize}
  \item \textbf{ResNet-50 + K–Means} y \textbf{DenseNet-121 + K–Means}
        alcanzan simultáneamente los valores más altos de \(\widehat S\) y
        \(\widehat{CH}\), indicando una separación nítida entre clusters.
  \item Los métodos aglomerativos tienden a obtener \(\widehat S\) ligeramente
        inferior pero muestran menor varianza en \(\widehat{DB}\),
        sugiriendo particiones algo más equilibradas.
  \item Spectral clustering no supera a K–Means en ninguna combinación,
        aunque mantiene una estabilidad apreciable frente a variaciones de \(k\).
\end{itemize}

%....................................................................
\subsubsection{Curvas \emph{elbow} y selección de $k$ óptimo}
%....................................................................

Para cada extractor (\textbf{ResNet-18, ResNet-50, DenseNet-121, VGG-16})
y algoritmo particional (\textbf{K–Means, Agglomerative, Spectral})
se calculó la variación de \(\widehat S\), \(\widehat{DB}\) y
\(\widehat{CH}\) al incrementar el número de clusters
\(k\in\{2,\dots,10\}\).
Las doce curvas resultantes se ilustran en la
Fig.~\ref{fig:elbow_grid}, donde cada subfigura corresponde a una pareja
\emph{extractor–algoritmo}.

\begin{figure}[ht]
  \centering
  % ---------- Fila 1: ResNet-18 ----------
  \subfloat[ResNet-18 + K-Means\label{fig:elbow_r18_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_kmeans}}\hfill
  \subfloat[ResNet-18 + Aggl.\label{fig:elbow_r18_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_agglomerative}}\hfill
  \subfloat[ResNet-18 + Spectral\label{fig:elbow_r18_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_spectral}}\\[0.8ex]

  % ---------- Fila 2: ResNet-50 ----------
  \subfloat[ResNet-50 + K-Means\label{fig:elbow_r50_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_kmeans}}\hfill
  \subfloat[ResNet-50 + Aggl.\label{fig:elbow_r50_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_agglomerative}}\hfill
  \subfloat[ResNet-50 + Spectral\label{fig:elbow_r50_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_spectral}}\\[0.8ex]

  % ---------- Fila 3: DenseNet-121 ----------
  \subfloat[DenseNet-121 + K-Means\label{fig:elbow_dn_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_kmeans}}\hfill
  \subfloat[DenseNet-121 + Aggl.\label{fig:elbow_dn_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_agglomerative}}\hfill
  \subfloat[DenseNet-121 + Spectral\label{fig:elbow_dn_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_spectral}}\\[0.8ex]

  % ---------- Fila 4: VGG-16 ----------
  \subfloat[VGG-16 + K-Means\label{fig:elbow_vgg_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_kmeans}}\hfill
  \subfloat[VGG-16 + Aggl.\label{fig:elbow_vgg_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_agglomerative}}\hfill
  \subfloat[VGG-16 + Spectral\label{fig:elbow_vgg_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_spectral}}
  \caption{Curvas \emph{elbow} de los tres índices internos
    (\(\widehat S\), \(\widehat{DB}\), \(\widehat{CH}\)) para cada
    combinación extractor–algoritmo.  El codo compartido por las tres
    métricas indica el rango de $k$ donde la partición deja de mejorar
    significativamente.}
  \label{fig:elbow_grid}
\end{figure}

\vspace{1ex}
\noindent\textbf{Hallazgos principales.}
\begin{itemize}
  \item En \textbf{ResNet-50} y \textbf{DenseNet-121} se observa un codo
        coherente de las tres métricas en \(k\approx4\)–\(5\),
        particularmente pronunciado en K–Means.
  \item Para \textbf{VGG-16} las curvas muestran una inflexión menos clara;
        \(\widehat S\) sugiere \(k=4\) mientras que \(\widehat{CH}\) se sigue
        incrementando hasta \(k=6\).
  \item \textbf{Agglomerative} tiende a un codo desplazado a
        \(k+1\) respecto de K–Means, reflejando su creación temprana de
        “grandes” conglomerados antes de afinar la estructura jerárquica.
  \item \textbf{Spectral} produce la pendiente más suave: su óptimo se
        determina por el primer punto donde
        \(\widehat S\) se estabiliza (generalmente \(k=4\)).
\end{itemize}

\vspace{1ex}
\paragraph{Número óptimo de clusters.}
Combinando la evidencia de la Fig.~\ref{fig:elbow_grid} con
la Tabla~\ref{tab:int_quality_partitional}, se adopta \(k^\ast=4\) para
ResNet-50 y DenseNet-121, y \(k^\ast=5\) para VGG-16.
ResNet-18 mostró menor estabilidad; se mantiene \(k^\ast=4\) por coherencia
comparativa.

%....................................................................
\subsubsection{Densidad: DBSCAN}
%....................................................................

La naturaleza no particional de DBSCAN exige evaluar diferentes umbrales de densidad.
En la Tabla~\ref{tab:int_quality_dbscan} se listan las 40 configuraciones probadas, variando \(\varepsilon\in[0.25,0.45]\) y \texttt{min\_samples}\(\in\{4,5\}\).

\begin{longtable}{lrrrrrr}
\caption{Métricas de calidad interna normalizadas para DBSCAN con diferentes hiperparámetros.}
\label{tab:int_quality_dbscan}\\
\hline
\textbf{model} & \textbf{eps} & \textbf{min\_samples} & \textbf{noise\_ratio} &
\textbf{silhouette} & \textbf{db\_inv} & \textbf{ch\_norm}\\
\hline
\endfirsthead
\caption[]{Métricas de calidad interna normalizadas para DBSCAN con diferentes hiperparámetros (cont.).}\\
\hline
\textbf{model} & \textbf{eps} & \textbf{min\_samples} & \textbf{noise\_ratio} &
\textbf{silhouette} & \textbf{db\_inv} & \textbf{ch\_norm}\\
\hline
\endhead
\hline
\multicolumn{7}{r}{\small Continúa en la página siguiente}\\
\hline
\endfoot
\hline
\endlastfoot
   resnet18 & 0.25 &            4 &         0.92 &            0.584 &   0.847 &    0.019 \\
   resnet18 & 0.25 &            5 &         0.95 &            0.597 &   0.825 &    0.034 \\
   resnet18 & 0.30 &            4 &         0.69 &            0.447 &   0.803 &    0.006 \\
   resnet18 & 0.30 &            5 &         0.74 &            0.458 &   0.771 &    0.011 \\
   resnet18 & 0.35 &            4 &         0.38 &            0.412 &   0.778 &    0.004 \\
   resnet18 & 0.35 &            5 &         0.42 &            0.422 &   0.783 &    0.007 \\
   resnet18 & 0.40 &            4 &         0.15 &            0.447 &   0.793 &    0.002 \\
   resnet18 & 0.40 &            5 &         0.16 &            0.451 &   0.804 &    0.003 \\
   resnet18 & 0.45 &            4 &         0.05 &            0.519 &   0.855 &    0.001 \\
   resnet18 & 0.45 &            5 &         0.05 &            0.614 &   0.955 &    0.005 \\
   resnet50 & 0.25 &            4 &         0.96 &            0.601 &   0.851 &    0.019 \\
   resnet50 & 0.25 &            5 &         0.97 &            0.651 &   0.888 &    0.024 \\
   resnet50 & 0.30 &            4 &         0.86 &            0.583 &   0.910 &    0.022 \\
   resnet50 & 0.30 &            5 &         0.90 &            0.587 &   0.916 &    0.032 \\
   resnet50 & 0.35 &            4 &         0.68 &            0.499 &   0.796 &    0.012 \\
   resnet50 & 0.35 &            5 &         0.73 &            0.548 &   0.831 &    0.027 \\
   resnet50 & 0.40 &            4 &         0.41 &            0.402 &   0.778 &    0.003 \\
   resnet50 & 0.40 &            5 &         0.46 &            0.406 &   0.765 &    0.006 \\
   resnet50 & 0.45 &            4 &         0.19 &            0.408 &   0.763 &    0.000 \\
   resnet50 & 0.45 &            5 &         0.22 &            0.418 &   0.775 &    0.001 \\
densenet121 & 0.25 &            4 &         0.96 &            0.683 &   0.948 &    0.033 \\
densenet121 & 0.25 &            5 &         0.97 &            0.685 &   0.925 &    0.042 \\
densenet121 & 0.30 &            4 &         0.82 &            0.552 &   0.855 &    0.019 \\
densenet121 & 0.30 &            5 &         0.86 &            0.565 &   0.847 &    0.025 \\
densenet121 & 0.35 &            4 &         0.56 &            0.432 &   0.784 &    0.004 \\
densenet121 & 0.35 &            5 &         0.61 &            0.444 &   0.777 &    0.009 \\
densenet121 & 0.40 &            4 &         0.27 &            0.414 &   0.748 &    0.001 \\
densenet121 & 0.40 &            5 &         0.30 &            0.424 &   0.759 &    0.002 \\
densenet121 & 0.45 &            4 &         0.09 &            0.445 &   0.767 &    0.001 \\
densenet121 & 0.45 &            5 &         0.11 &            0.477 &   0.780 &    0.003 \\
      vgg16 & 0.25 &            4 &         0.99 &            0.701 &   1.000 &    0.050 \\
      vgg16 & 0.25 &            5 &         0.99 &            0.709 &   0.997 &    0.066 \\
      vgg16 & 0.30 &            4 &         0.89 &            0.546 &   0.857 &    0.020 \\
      vgg16 & 0.30 &            5 &         0.93 &            0.568 &   0.868 &    0.035 \\
      vgg16 & 0.35 &            4 &         0.69 &            0.388 &   0.784 &    0.001 \\
      vgg16 & 0.35 &            5 &         0.73 &            0.419 &   0.768 &    0.013 \\
      vgg16 & 0.40 &            4 &         0.40 &            0.391 &   0.768 &    0.000 \\
      vgg16 & 0.40 &            5 &         0.44 &            0.395 &   0.754 &    0.000 \\
      vgg16 & 0.45 &            4 &         0.16 &            0.429 &   0.787 &    0.000 \\
      vgg16 & 0.45 &            5 &         0.19 &            0.450 &   0.764 &    0.001 \\
\end{longtable}

\begin{itemize}
  \item Las mejores puntuaciones de \(\widehat S\) y \(\widehat{DB}\) se obtienen con \(\varepsilon=0.30\)–\(0.35\), aunque a costa de una tasa de ruido (\textit{noise\_ratio}) del 60--90~\%.
  \item La métrica \(\widehat{CH}\) penaliza fuertemente la presencia de ruido, arrojando valores cercanos a \(0\) incluso en casos con buena cohesión interna; por ello se interpreta con cautela.
  \item Frente a los métodos particionales, DBSCAN ofrece clusters densos y compactos, útiles para aislar motivos morfológicamente homogéneos, pero reduce su cobertura sobre el conjunto total de motivos.
\end{itemize}

%....................................................................
\subsubsection{Síntesis de las mejores configuraciones}
%....................................................................

Para facilitar la comparación se selecciona, por cada
\textit{extractor × algoritmo}, la ejecución con mayor media geométrica de
\((\widehat S,\widehat{DB},\widehat{CH})\).
La Tabla~\ref{tab:int_quality_best} resume dichos “ganadores”.

\begin{table}[ht]
  \centering
  \caption{Resumen de las mejores configuraciones por extractor y algoritmo, usando la media geométrica de los tres índices normalizados como criterio global.}
  \label{tab:int_quality_best}
  \begin{tabular}{llccc}
    \hline
    \textbf{Extractor} & \textbf{Algoritmo} & \textbf{Silhouette} & \textbf{Davies–Bouldin} & \textbf{Calinski–Harabasz} \\ \hline
    DenseNet-121 & K–Means        & 0.553 & 0.182 & 0.905 \\
                 & Agglomerative  & 0.544 & 0.109 & 0.738 \\
                 & Spectral       & 0.549 & 0.175 & 0.818 \\
                 & DBSCAN         & 0.685 & 0.915 & 0.037 \\ \hline
    ResNet-18    & K–Means        & 0.557 & 0.132 & 0.787 \\
                 & Agglomerative  & 0.560 & 0.122 & 0.636 \\
                 & Spectral       & 0.546 & 0.000 & 0.682 \\
                 & DBSCAN         & 0.614 & 0.951 & 0.000 \\ \hline
    ResNet-50    & K–Means        & 0.559 & 0.221 & 1.000 \\
                 & Agglomerative  & 0.548 & 0.045 & 0.720 \\
                 & Spectral       & 0.544 & 0.068 & 0.710 \\
                 & DBSCAN         & 0.651 & 0.872 & 0.019 \\ \hline
    VGG-16       & K–Means        & 0.559 & 0.229 & 0.990 \\
                 & Agglomerative  & 0.552 & 0.163 & 0.870 \\
                 & Spectral       & 0.556 & 0.219 & 0.951 \\
                 & DBSCAN         & 0.709 & 1.000 & 0.061 \\ \hline
  \end{tabular}
\end{table}

\begin{enumerate}
  \item \textbf{ResNet-50 + K–Means} resulta la combinación más consistente al maximizar simultáneamente los tres índices.
  \item \textbf{DenseNet-121 + K–Means} y \textbf{DenseNet-121 + Spectral} muestran un rendimiento muy similar, confirmando que características densas extraídas de capas profundas favorecen la separabilidad interna.
  \item \textbf{DBSCAN} sobresale solo en \(\widehat{DB}\); su aplicabilidad queda restringida a casos donde la detección de “núcleos” densos sea prioritaria sobre cubrir la totalidad del corpus.
\end{enumerate}

En conjunto, los resultados preliminares indican que la elección del \emph{extractor} incide más sobre la calidad interna que la selección del \emph{algoritmo}.
Las configuraciones basadas en ResNet-50 y DenseNet-121 se mantendrán como candidatas para las comparaciones externas con la clasificación arqueológica.

%....................................................................
\subsubsection{Visualización t-SNE de las configuraciones ganadoras}
%....................................................................

Con el $k^\ast$ seleccionado, se proyectaron los embeddings de motivos
mediante t-SNE (perplejidad = 30, 1\,000 iteraciones) para las tres
configuraciones de mayor desempeño global
(ResNet-50 + K–Means, DenseNet-121 + K–Means, DenseNet-121 + Spectral).
Las Figuras~\ref{fig:tsne_resnet50_kmeans}–\ref{fig:tsne_dense_spectral}
ilustran la separabilidad visual de los clusters.

\begin{figure}[ht]
  \centering
  % ----------- t-SNE plots -----------
  \subfloat[ResNet-50 + K--Means ($k=4$)\label{fig:tsne_resnet50_kmeans}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_resnet50_kmeans_k4}}\hfill
  \subfloat[DenseNet-121 + K--Means ($k=4$)\label{fig:tsne_dense_kmeans}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_densenet121_kmeans_k4}}\hfill
  \subfloat[DenseNet-121 + Spectral ($k=4$)\label{fig:tsne_dense_spectral}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_densenet121_spectral_k4}}

  %----- caption + label -----
  \caption{Proyección t-SNE de las configuraciones con mayor media
    geométrica de los índices internos. Cada color representa un cluster;
    la separación espacial respalda la coherencia semántica discutida.}%
  \label{fig:tsne_best}
\end{figure}

\vspace{1ex}
\paragraph{DBSCAN y gráficas de Silhouette.}
Para DBSCAN las curvas de Silhouette frente a \(\varepsilon\) se relegan al
Apéndice~B: ilustran que la calidad interna mejora hasta
\(\varepsilon\approx0.35\) antes de diluirse por exceso de ruido.
Dado que DBSCAN no optimiza $k$, estas gráficas se usan solo como referencia
de densidad y no influyen en la selección final de configuraciones.

\subsection{Comparación con Clasificación Arqueológica}
\begin{itemize}
  \item Matriz de confusión entre clusters y las 6 categorías zoomórficas manuales.
  \item Métricas de homogeneidad y completitud para las tres configuraciones mejor puntuadas.
  \item Ejemplos visuales (collages) de clusters “puros” vs.\ mezclados.
\end{itemize}

\subsection{Síntesis de Resultados No Supervisados}
\begin{itemize}
  \item Resumen de qué configuraciones agrupan mejor motivos similares.
  \item Comentarios de la arqueóloga sobre la coherencia semántica de los conglomerados.
\end{itemize}

%----------------------------------------------------------------------
\section{Comparación Cruzada y Costes Computacionales}

\begin{itemize}
  \item Tabla de tiempo de entrenamiento/inferencia y uso de VRAM por modelo.
  \item Discusión sobre la relación coste–beneficio entre arquitecturas y técnicas de preprocesamiento.
  \item Implicaciones para la adopción práctica en proyectos arqueológicos.
\end{itemize}
