\chapter{Resultados}\label{ch:resultados}

\section{Estructura general}
En este capítulo se presentan los hallazgos cuantitativos y cualitativos obtenidos a partir de los dos experimentos principales:

\begin{enumerate}
  \item \textbf{Detección Supervisada de Motivos}
  \item \textbf{Agrupamiento No Supervisado de Motivos}
\end{enumerate}

Cada bloque de resultados conserva la lógica de las fases descritas en el capítulo de Materiales y Métodos para facilitar la lectura cruzada.

\section{Detección Supervisada de Motivos}

Esta sección presenta los resultados de las cinco fases de detección supervisada de motivos.
Se optimizan cuatro detectores preentrenados —YOLOv5, RetinaNet, Faster R CNN y Deformable DETR— combinados con cinco variantes de preprocesamiento que incluyen la versión base sin filtros.
El desempeño se resume mediante mAP$_{0.5}$ y mAR$_{100}$, acompañado de ejemplos visuales que evidencian aciertos y errores característicos.

\subsection{Fase 1 — Prueba inicial}
\label{ssec:fase1}

\paragraph{Curvas de Función de Pérdida para Conjuntos de Entrenamiento y Validación.}
La Figura~\ref{fig:phase1_small_multiples} sintetiza, en un \emph{small-multiples} \footnote{El término, popularizado por Edward Tufte, designa una cuadrícula de gráficos de igual formato y escala que permite comparar visualmente varias series de datos de un vistazo.}, la evolución de funciones de pérdida para los conjuntos de entrenamiento y validación, respectivamente (filas superiores), junto con los indicadores de desempeño mAP$_{0.5}$ y mAR$_{100}$ (filas inferiores) para las cuatro arquitecturas que se evalúan.
Cada columna corresponde a un modelo y cada punto representa una época.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{Images/phase1_small_multiples}
  \caption[Curvas de pérdida y métricas de la Fase 1]{Evolución de las pérdidas y métricas durante la prueba inicial. Las líneas sólidas muestran los valores por época.}
  \label{fig:phase1_small_multiples}
\end{figure}

\paragraph{Desempeño al cierre de la fase.}
El Cuadro~\ref{tab:fase1_final} resume los valores que se obtienen en la última época entrenada de cada red.
YOLOv5 lidera en mAP$_{0.5}$ (30 \%), seguido por Deformable DETR (18 \%).
Faster R–CNN alcanza 5 \% y RetinaNet se mantiene por debajo del 1 \%.

\begin{table}[!ht]
  \centering
  \begin{tabular}{lcccc}
    \hline
    \textbf{Modelo} & \textbf{Época} & \textbf{Val\,loss} & \textbf{mAP$_{0.5}$ (\%)} & \textbf{mAR$_{100}$ (\%)}\\
    \hline
    Faster R–CNN        & 8  & 1.69  & 5.4  & 10.2 \\
    RetinaNet           & 8  & 1.28  & 0.15 & 13.0 \\
    Deformable DETR     & 10 & 275.8 & 17.7 & 38.1 \\
    YOLOv5              & 30 & 5.02  & 29.9 & 28.0 \\
    \hline
  \end{tabular}
  \caption[Resumen cuantitativo de la Fase 1]{Resultados al finalizar la prueba inicial. Los porcentajes se obtienen multiplicando los valores decimales por 100.}
  \label{tab:fase1_final}
\end{table}

\paragraph{Breve discusión técnica.}
\begin{itemize}
  \item \textbf{Estabilidad de la convergencia.}
        YOLOv5 muestra una disminución casi monótona de \texttt{val\_loss} y un incremento sostenido de mAP y mAR a lo largo de las 30 épocas, con una brecha mínima respecto a la \texttt{train\_loss}.
        En Deformable DETR las pérdidas oscilan de forma marcada (esperable en esta arquitectura si se observan pocas épocas), pero las métricas de precisión exhiben una tendencia netamente ascendente.

  \item \textbf{Ausencia de sobre-ajuste visible.}
        En los cuatro modelos la \texttt{val\_loss} desciende en paralelo (o solo ligeramente por encima) de la \texttt{train\_loss}.
        Ninguna curva revierte su tendencia dentro del rango observado, por lo que no se aprecian indicios claros de sobre-ajuste durante las primeras 8–10 épocas (30 en el caso de YOLOv5).

  \item \textbf{Sensibilidad a la tasa de aprendizaje.}
        RetinaNet muestra mejoras modestas: la pendiente de mAP/mAR se atenúa a partir de la época 6, lo que sugiere que la LR inicial, compartida por todas las pruebas, podría ser sub-óptima para esta arquitectura.
        Por el contrario, YOLOv5 mantiene una convergencia rápida y estable con la misma configuración, indicando mayor robustez frente a la elección del hiperparámetro.
\end{itemize}

\paragraph{Criterio de avance.}
Dado que RetinaNet no supera el umbral del 1 \% en mAP$_{0.5}$ y evidencia sobre-ajuste prematuro aun tras ajustes mínimos de LR, se descarta su inclusión en la Fase 2.
Las tres arquitecturas restantes continúan: YOLOv5 y Faster R–CNN (ambas con filtrado bilateral) sirven de referencias de precisión y robustez, mientras que Deformable DETR sin preprocesamiento se mantiene como alternativa de alta recuperación.

\vspace{0.5em}
Los resultados de esta fase constituyen la línea base sobre la cual se desarrollan los experimentos de preprocesamiento y ajuste fino presentados en las secciones siguientes.

\subsection{Fase 2 — Comparación de Preprocesamientos}
\label{ssec:fase2}

\paragraph{Diseño experimental.}
Se evalúan cinco técnicas de preprocesamiento —\textit{Base} (sin filtros), \textit{Bilateral Filter}, \textit{CLAHE}, \textit{Unsharp Masking} y \textit{Laplacian Pyramid}— aplicadas a las cuatro arquitecturas de la Fase 1.
Para cada combinación se registra el mayor mAP\(_{0.5}\) dentro de la ventana de entrenamiento, y se refleja en la tabla~\ref{tab:fase2_map}.

\begin{table}[!ht]
  \centering
  \begin{tabular}{lccccc}
    \hline
                     & \multicolumn{5}{c}{\textbf{mAP\(_{0.5}\) máximo [\%]}}\\
    \cline{2-6}
    \textbf{Modelo}  & \textbf{Base} & \textbf{Bilateral} & \textbf{CLAHE} & \textbf{Unsharp} & \textbf{Laplacian}\\
    \hline
    Faster R–CNN         & 5.4  & \textbf{6.5} & 5.5  & 5.4  & 4.9  \\
    RetinaNet$^\dagger$  & 0.15 & 0.15         & 0.17 & 0.16 & 0.17 \\
    Deformable DETR      & \textbf{17.7} & 10.6 & 17.1 & 16.3 & 16.8 \\
    YOLOv5               & 29.9 & 31.1 & \textbf{31.5} & 30.3 & 31.0 \\
    \hline
  \end{tabular}
  \caption[Mejor mAP por técnica de preprocesamiento]{Resumen de la Fase 2. Se muestra el mayor mAP\(_{0.5}\) obtenido (en porcentaje). $^\dagger$RetinaNet se incluye para completitud, pero sus valores permanecen por debajo del 1 \%.}
  \label{tab:fase2_map}
\end{table}


\paragraph{Variabilidad de los resultados.}
La Figura~\ref{fig:fase2_ridges} muestra un gráfico tipo \emph{ridgeline}\footnote{También denominado \emph{joyplot} o gráfico de crestas, útil para comparar distribuciones de densidad en paralelo.} con la distribución de mAP\(_{0.5}\) obtenida para cada técnica de preprocesamiento durante la Fase 2.
Se representan en total \(n=240\) mediciones (5 filtros \(\times\) 4 detectores \(\times\) épocas), lo que permite captar tanto la variación intra-modelo como la evolución temporal.

\begin{itemize}
  \item Los filtros \textit{Bilateral} y \textit{CLAHE} concentran la mayor parte de su densidad entre \(0.20\) y \(0.25\), indicando un rendimiento sistemáticamente superior al caso \textit{Base} (sin filtrado), cuya cresta se desplaza hacia la izquierda.
  \item \textit{Unsharp Masking} y la \textit{Pyrámide Laplaciana} muestran colas más extensas: alcanzan valores altos de mAP\(_{0.5}\) en algunos experimentos, pero con mayor dispersión, lo que sugiere sensibilidad al modelo o a la época de entrenamiento.
  \item En ausencia de sobre-representación de un detector concreto, las diferencias observadas pueden atribuirse principalmente al preprocesamiento aplicado.
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{Images/phase2_ridgelines}
  \caption[Distribución de mAP\(_{0.5}\) por técnica]{Comparación de las distribuciones de mAP\(_{0.5}\) (160 mediciones en total).
           Cada cresta resume la densidad de una técnica de preprocesamiento: un desplazamiento hacia la derecha implica valores más altos de precisión.}
  \label{fig:fase2_ridges}
\end{figure}

\paragraph{Impacto relativo.}
La Figura~\ref{fig:fase2_deltas} compara cada combinación \(\langle\text{detector},\ \text{filtro}\rangle\) con su respectiva línea \textit{Base} (sin preprocesamiento).
La “ganancia relativa” se define como
\[
  \Delta = \bar{m}_{\text{filtro}} - \bar{m}_{\text{Base}},
\]
donde \(\bar{m}\) es la media de la métrica (mAP\(_{0.5}\) a la izquierda, mAR\(_{100}\) a la derecha) sobre las ocho épocas analizadas.
Los valores se muestran con tres decimales; un incremento de \(+0.011\) equivale a \(+1.1\) puntos porcentuales (pp) porque ambas métricas están acotadas en \([0,1]\).

\begin{itemize}
  \item \textbf{Mejoras notables.}
        El filtro \emph{Bilateral} aporta la mayor ganancia absoluta a Faster R–CNN (+0.011 en mAP\(_{0.5}\)) y a YOLOv5 (+0.011).
        En términos de mAR\(_{100}\), la ventaja se amplía hasta +0.024 pp para YOLOv5.
  \item \textbf{Efecto neutro a leve.}
        \emph{CLAHE}, \emph{Laplacian Pyramid} y \emph{Unsharp Masking} producen mejoras menores (+0.015 pp) o prácticamente nulas en Faster R–CNN.
  \item \textbf{Degradación en Deformable DETR.}
        Para este detector, el preprocesamiento resulta contraproducente: el filtro \emph{Bilateral} reduce la mAP\(_{0.5}\) en –0.033 pp y la mAR\(_{100}\) en –0.029 pp; incluso el mejor caso (\emph{CLAHE}) apenas compensa esta caída.
\end{itemize}

\begin{figure*}[!ht]
  \centering
  \includegraphics[width=.48\textwidth]{Images/phase2_delta_map_heat}\hfill
  \includegraphics[width=.48\textwidth]{Images/phase2_delta_mar_heat}
  \caption[Diferencia relativa en mAP y mAR]{Matrices de \(\Delta\) respecto a la condición \textit{Base}.
           Izquierda: mAP\(_{0.5}\);\; derecha: mAR\(_{100}\).
           Un valor positivo (verde) indica mejora; negativo (rojo), degradación.}
  \label{fig:fase2_deltas}
\end{figure*}


\paragraph{Mejores ejecuciones.}
La Figura~\ref{fig:fase2_bestruns} ilustra las curvas de funciones de pérdida y métricas de las tres combinaciones con mayor potencial: Faster R–CNN + Bilateral, YOLOv5 + Bilateral y Deformable DETR + Base.

\begin{figure}[!ht]
  \centering
  \includegraphics[height=0.8\textheight,keepaspectratio]{Images/phase2_best_runs}
  \caption[Evolución de las mejores configuraciones]{Curvas de \texttt{loss} y métricas para las configuraciones preseleccionadas en la Fase 2.}
  \label{fig:fase2_bestruns}
\end{figure}

\vspace{0.5em}
En síntesis, \textbf{Bilateral Filter} emerge como el preprocesamiento más robusto para las arquitecturas basadas en anclajes, mientras que Deformable DETR preserva su rendimiento óptimo con datos sin filtrar.

\subsection{Fase 3 — Selección de Configuraciones Óptimas}
\label{ssec:fase3}

\paragraph{Ranking final.}
A partir de la Fase 2 se entrenan a convergencia prolongada las tres combinaciones mejor posicionadas.
El Cuadro~\ref{tab:fase3_ranking} ordena los resultados finales según mAP\(_{0.5}\) y mAR\(_{100}\).

\begin{table}[!ht]
  \centering
  \begin{tabular}{lccc}
    \hline
    \textbf{Posición} & \textbf{Modelo + Preproc.} & \textbf{mAP\(_{0.5}\) [\%]} & \textbf{mAR\(_{100}\) [\%]}\\
    \hline
    1\textsuperscript{º} & YOLOv5 + Bilateral           & \textbf{31.1} & 30.5\\
    2\textsuperscript{º} & Deformable DETR + Base       & 17.7 & \textbf{38.1}\\
    3\textsuperscript{º} & Faster R–CNN + Bilateral     & 6.5  & 10.7\\
    \hline
  \end{tabular}
  \caption[Ranking de configuraciones óptimas]{Desempeño final de las tres configuraciones seleccionadas.}
  \label{tab:fase3_ranking}
\end{table}

\paragraph{Justificación de la elección.}
\begin{itemize}
  \item \textbf{YOLOv5 + Bilateral} alcanza el mayor mAP\(_{0.5}\) sin sacrificar recuperación, ofrece el mejor equilibrio global y mantiene tiempos de inferencia competitivos.
  \item \textbf{Deformable DETR + Base} domina en mAR\(_{100}\) (38 \%), revela una notable capacidad para recuperar motivos poco frecuentes, aunque con precisión absoluta menor.
  \item \textbf{Faster R–CNN + Bilateral} mejora levemente sobre su línea \textit{Base}, pero su margen de ganancia resulta limitado frente a las dos alternativas anteriores.
\end{itemize}

Por tanto, \textbf{YOLOv5 con filtrado bilateral} se adopta como configuración principal para los análisis cuantitativos subsecuentes, y \textbf{Deformable DETR sin preprocesamiento} y \textbf{Faster R-CNN con filtrado bilateral} se mantienen como referencia de alta recuperación en contextos complementarios.

\subsection{Fase 4 — Entrenamiento Integral}
\label{ssec:fase4_integral}

En esta fase se completó el entrenamiento exhaustivo de las tres arquitecturas seleccionadas
(YOLOv5, Deformable DETR y Faster~R–CNN), cada una con la cantidad de épocas definida en el plan experimental
(YOLOv5: 60, Deformable~DETR: 25, Faster~R–CNN: 30).

La Figura~\ref{fig:phase4_curves} ilustra la evolución temporal de las pérdidas y las métricas en los conjuntos de \textit{train} y \textit{val}.
Se observan tres comportamientos bien diferenciados:

\begin{itemize}
  \item \textbf{YOLOv5} presenta una caída estable de \texttt{train\_loss} y \texttt{val\_loss}, acompañada de mejoras sostenidas en mAP\(_{0.5}\) y mAR\(_{100}\).
  \item \textbf{Deformable DETR} exhibe oscilaciones pronunciadas propias de su esquema de \emph{warm-up} y del balance entre la \emph{Hungarian matching loss} y la regresión de cajas; aun así, la tendencia global de mAR\(_{100}\) es ascendente.
  \item \textbf{Faster R–CNN} converge de forma más gradual; sus curvas muestran un descenso consistente, pero con menor pendiente que YOLOv5.
\end{itemize}

Para una comparación sintética, la Figura~\ref{fig:phase4_bars} agrupa los mejores valores de mAP\(_{0.5}\) y mAR\(_{100}\) alcanzados en validación.
La Tabla~\ref{tab:phase4_val} aporta la referencia numérica exacta:

\begin{table}[!ht]
  \centering
  \caption{Mejores métricas de validación obtenidas en la Fase 4.
           El conjunto \textit{test} se reserva para la Fase 5.}
  \label{tab:phase4_val}
  \begin{tabular}{lcc}
    \hline
    Modelo & mAP\(_{0.5}\)\,↑ & mAR\(_{100}\)\,↑\\
    \hline
    YOLOv5 (\textit{Bilateral})        & 0.52 & 0.46\\
    Deformable DETR (\textit{Base})    & 0.16 & 0.36\\
    Faster R--CNN (\textit{Bilateral}) & 0.11 & 0.21\\
    \hline
  \end{tabular}
\end{table}

\begin{figure}[!ht]
  \centering
  \includegraphics[height=0.8\textheight,keepaspectratio]{Images/phase4_curves}
  \caption[Evolución de las métricas durante la Fase 4 (resumen)]%
          {Evolución de las métricas durante la Fase 4.%
          \textbf{YOLOv5} eleva mAP\(_{0.5}\) de 0.15 a 0.45 en las primeras \(\sim\)15 épocas y luego se estabiliza, reflejando una convergencia rápida.%
          \textbf{Deformable DETR} presenta oscilaciones pronunciadas en las pérdidas debidas al incremento lineal inicial de la tasa de aprendizaje (\emph{warm-up})\footnotemark, aunque la tendencia media de mAR\(_{100}\) es ascendente.%
          \textbf{Faster R--CNN} requiere unas 20 épocas para aproximarse a su máximo, por lo que converge más lentamente en términos de épocas efectivas.}%
  \label{fig:phase4_curves}
\end{figure}

\footnotetext{Durante las tres primeras épocas se aplica un \emph{warm-up} lineal del \emph{learning rate}.}


\begin{figure}[!ht]
  \centering
  \includegraphics[width=.9\textwidth]{Images/phase4_summary_bars}
  \caption{Comparación de los mejores mAP\(_{0.5}\) y mAR\(_{100}\)
           por modelo.  YOLOv5 supera al resto con un margen
           considerable.}
  \label{fig:phase4_bars}
\end{figure}

En términos de precisión (mAP\(_{0.5}\)), YOLOv5 aventaja al segundo mejor modelo en \(\sim\)36~pp y,
en capacidad de recuperación (mAR\(_{100}\)), la brecha es de 10~pp respecto a Deformable DETR.
Estas diferencias motivan la selección preliminar de YOLOv5 como candidato principal para la fase de validación experta
(Sección~\ref{ssec:fase5_experta}), sin descartar aportar observaciones cualitativas derivadas del modelo Deformable DETR.

\paragraph{Inspección cualitativa.}
La Fig.~\ref{fig:yolov5_val} ilustra detecciones de YOLOv5 sobre el conjunto de validación.
El modelo localiza correctamente la mayoría de los motivos, incluso en presencia de ruido de superficie.
Sin embargo:

\begin{itemize}
  \item Se omiten algunos motivos cuando se superponen (\emph{overlay}) animales y manos.
  \item Varias predicciones presentan confianzas entre 0.3 y 0.7, indicio de que el entrenamiento aún no alcanza su máximo potencial.
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{Images/yolov5_val}
  \caption{Ejemplos de predicción con YOLOv5 en validación. Azul: “Animal”; cian: “Hand”.}
  \label{fig:yolov5_val}
\end{figure}

\subsection{Fase 5 — Validación Experta}
\label{ssec:fase5_experta}

La validación cualitativa se basa en la matriz de confusión de YOLOv5 (Fig.~\ref{fig:yolov5_cm}) y en la inspección visual de la arqueóloga.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=.7\textwidth]{Images/yolov5_cm}
  \caption{Matriz de confusión de YOLOv5 en validación.
           Filas: etiquetas predichas; columnas: etiquetas verdaderas.}
  \label{fig:yolov5_cm}
\end{figure}

\paragraph{Interpretación de resultados.}

\begin{itemize}
  \item \textbf{Aciertos.}
        El modelo acierta 997 de las instancias de “Animal” y 418 de “Hand”, evidenciando buena discriminación cuando el motivo es claro.
  \item \textbf{Falsos negativos.}
        Las mayores pérdidas provienen de 1 247 “Animal” y 558 “Hand” no detectados (\emph{predicted background}).
        Esto confirma que la red tiende a omitir motivos tenues o parcialmente superpuestos.
  \item \textbf{Falsos positivos menores.}
        Sólo 10 “Hand” se confunden con “Animal” y 23 “Animal” se confunden con “Hand”, lo que indica que, cuando detecta un motivo, la clasificación suele ser correcta.
  \item \textbf{Confianza moderada.}
        Las puntuaciones de 0.3–0.7 observadas en la Fig.~\ref{fig:yolov5_val} sugieren que el modelo aún puede beneficiarse de más épocas o de \emph{fine-tuning} focalizado.
\end{itemize}

\paragraph{Conclusión preliminar.}
YOLOv5 demuestra ser útil como herramienta de cribado (\emph{screening}) en campo: identifica la mayoría de los motivos visibles y mantiene una tasa baja de confusión entre clases.
No obstante, la especialista recomienda:

\begin{enumerate}
  \item Añadir ejemplos con superposición severa y bajo contraste para mejorar la recuperación de manos y figuras erosionadas.
  \item Incrementar las iteraciones de entrenamiento o aplicar técnicas de focal loss para elevar la confianza media de las predicciones.
\end{enumerate}
Estos ajustes se contemplan antes del despliegue definitivo en trabajo de campo.

%----------------------------------------------------------------------
\section{Agrupamiento No Supervisado de Motivos}

El propósito de esta sección es indagar si los motivos rupestres se agrupan de forma natural a partir de sus rasgos visuales, prescindiendo de la clasificación arqueológica pre-existente.
Para ello se concatenaron descriptores extraídos con cuatro arquitecturas profundas (\texttt{densenet121}, \texttt{resnet18}, \texttt{resnet50} y \texttt{vgg16}) con cuatro algoritmos de agrupamiento (\texttt{k}-means, agrupamiento espectral, aglomerativo jerárquico y \texttt{DBSCAN}).

En los métodos que requieren fijar el número de grupos se ensayó un rango amplio de $k$, mientras que los esquemas basados en densidad determinaron el total de grupos a partir de sus propios parámetros.
La calidad interna de cada combinación se evaluó mediante homogeneidad ($H$) y completitud ($C$), y los resultados más prometedores se sometieron a una inspección cualitativa por parte de una especialista, que revisó tanto una selección dirigida de imágenes como un muestreo aleatorio por grupo.

Las subsecciones siguientes presentan primero las métricas cuantitativas de coherencia interna y, luego, las observaciones cualitativas que revelan la influencia predominante de la temperatura de color frente a la morfología de los motivos.

\subsection{Calidad Interna de Grupos}

En esta sección se evalúa la \emph{calidad interna} de los grupos obtenidos con cada combinación de extractor de características y algoritmo de agrupamiento.
Primero se analizan los métodos \emph{particionales} —K–Means, Agglomerative y Spectral— comparando el efecto de \(k\) sobre los índices \(\widehat S\), \(\widehat{DB}\) y \(\widehat{CH}\).
A continuación se examina el enfoque basado en densidad (DBSCAN), explorando su sensibilidad a \(\varepsilon\) y \texttt{min\_samples}.
Las subsubsecciones presentan (i) tablas con las mejores combinaciones según los tres índices normalizados, (ii) curvas \emph{elbow} para la selección de \(k\) óptimo y (iii) visualizaciones t-SNE que ilustran la separabilidad de los grupos.

%....................................................................
\subsubsection{Particionales: K–Means, Agglomerative, Spectral}
%....................................................................

\label{ssec:int_quality_partitional}

Se evaluaron \(108\) combinaciones
\textit{extractor} × \textit{algoritmo} × \(k\) (ver
Tabla~\ref{tab:app:int_quality_partitional} en el Apéndice).
En el cuerpo del capítulo sólo se reseñan las configuraciones que
obtienen simultáneamente valores altos de \(\widehat S\) y
\(\widehat{CH}\) —es decir, las que maximizan la cohesión intra-grupo
y la separación entre grupos.

\begin{table}[ht]
  \centering
  \caption{Mejores combinaciones según \(\widehat S\) y \(\widehat{CH}\).}
  \label{tab:int_quality_top}
  \begin{tabular}{lllrrr}
    \hline
    \textbf{Extractor} & \textbf{Algoritmo} & \(\mathbf{k}\)
      & \(\widehat S\) & \(\widehat{DB}\) & \(\widehat{CH}\) \\
    \hline
    ResNet-50    & K–Means & 2 & 0.559 & 0.336 & 1.000 \\
    VGG-16       & K–Means & 2 & 0.559 & 0.343 & 0.990 \\
    DenseNet-121 & K–Means & 2 & 0.553 & 0.303 & 0.905 \\
    ResNet-18    & K–Means & 2 & 0.557 & 0.261 & 0.788 \\
    \hline
  \end{tabular}
\end{table}

Se observa que:

\begin{itemize}
  \item \textbf{ResNet-50 + K–Means} y \textbf{DenseNet-121 + K–Means}
        lideran el ranking al exhibir los máximos
        \(\widehat S\) y \(\widehat{CH}\), señalando particiones con
        grupos densos y bien separados.
  \item Aunque los métodos aglomerativos producen valores de
        \(\widehat{DB}\) ligeramente más estables,
        su \(\widehat S\) típico es inferior,
        lo que sugiere límites menos definidos entre grupos.
  \item Spectral agrupamiento no supera a K–Means en ninguno de los
        extractores, pero mantiene una varianza reducida frente a cambios
        de \(k\), lo que podría ser ventajoso en tareas sensibles a la
        estabilidad.
\end{itemize}

%....................................................................
\subsubsection{Curvas \emph{elbow} y selección de $k$ óptimo}
%....................................................................

Para cada extractor (\textbf{ResNet-18, ResNet-50, DenseNet-121, VGG-16})
y algoritmo particional (\textbf{K–Means, Agglomerative, Spectral})
se calculó la variación de \(\widehat S\), \(\widehat{DB}\) y
\(\widehat{CH}\) al incrementar el número de grupos
\(k\in\{2,\dots,10\}\).
Las doce curvas resultantes se ilustran en la
Fig.~\ref{fig:elbow_grid}, donde cada subfigura corresponde a una pareja
\emph{extractor–algoritmo}.

\begin{figure}[!h]
  \centering
  % ---------- Fila 1: ResNet-18 ----------
  \subfloat[ResNet-18 + K-Means\label{fig:elbow_r18_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_kmeans}}\hfill
  \subfloat[ResNet-18 + Aggl.\label{fig:elbow_r18_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_agglomerative}}\hfill
  \subfloat[ResNet-18 + Spectral\label{fig:elbow_r18_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet18_spectral}}\\[0.8ex]

  % ---------- Fila 2: ResNet-50 ----------
  \subfloat[ResNet-50 + K-Means\label{fig:elbow_r50_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_kmeans}}\hfill
  \subfloat[ResNet-50 + Aggl.\label{fig:elbow_r50_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_agglomerative}}\hfill
  \subfloat[ResNet-50 + Spectral\label{fig:elbow_r50_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_resnet50_spectral}}\\[0.8ex]

  % ---------- Fila 3: DenseNet-121 ----------
  \subfloat[DenseNet-121 + K-Means\label{fig:elbow_dn_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_kmeans}}\hfill
  \subfloat[DenseNet-121 + Aggl.\label{fig:elbow_dn_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_agglomerative}}\hfill
  \subfloat[DenseNet-121 + Spectral\label{fig:elbow_dn_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_densenet121_spectral}}\\[0.8ex]

  % ---------- Fila 4: VGG-16 ----------
  \subfloat[VGG-16 + K-Means\label{fig:elbow_vgg_km}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_kmeans}}\hfill
  \subfloat[VGG-16 + Aggl.\label{fig:elbow_vgg_aggl}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_agglomerative}}\hfill
  \subfloat[VGG-16 + Spectral\label{fig:elbow_vgg_sp}]{%
    \includegraphics[width=.30\textwidth]{Images/elbow_vgg16_spectral}}
  \caption{Curvas \emph{elbow} de los tres índices internos
    (\(\widehat S\), \(\widehat{DB}\), \(\widehat{CH}\)) para cada
    combinación extractor–algoritmo.  El codo compartido por las tres
    métricas indica el rango de $k$ donde la partición deja de mejorar
    significativamente.}
  \label{fig:elbow_grid}
\end{figure}

\vspace{1ex}
\noindent\textbf{Hallazgos principales.}
\begin{itemize}
  \item En \textbf{ResNet-50} y \textbf{DenseNet-121} se observa un codo
        coherente de las tres métricas en \(k\approx4\)–\(5\),
        particularmente pronunciado en K–Means.
  \item Para \textbf{VGG-16} las curvas muestran una inflexión menos clara;
        \(\widehat S\) sugiere \(k=4\) mientras que \(\widehat{CH}\) se sigue
        incrementando hasta \(k=6\).
  \item \textbf{Agglomerative} tiende a un codo desplazado a
        \(k+1\) respecto de K–Means, reflejando su creación temprana de
        “grandes” conglomerados antes de afinar la estructura jerárquica.
  \item \textbf{Spectral} produce la pendiente más suave: su óptimo se
        determina por el primer punto donde
        \(\widehat S\) se estabiliza (generalmente \(k=4\)).
\end{itemize}

\vspace{1ex}
\paragraph{Número óptimo de grupos.}
Combinando la evidencia de la Fig.~\ref{fig:elbow_grid} con
la Tabla~\ref{tab:app:int_quality_partitional}, se adopta \(k^\ast=4\) para
ResNet-50 y DenseNet-121, y \(k^\ast=5\) para VGG-16.
ResNet-18 mostró menor estabilidad; se mantiene \(k^\ast=4\) por coherencia
comparativa.

%....................................................................
\subsubsection{Densidad: DBSCAN}
%....................................................................

DBSCAN se evaluó sobre \(40\) combinaciones de hiperparámetros
\(\varepsilon\in[0.25,0.45]\) y \texttt{min\_samples}\(\in\{4,5\}\)
(la tabla completa figura en el
Apéndice, Tabla~\ref{tab:app:int_quality_dbscan}).
A continuación se presentan sólo las configuraciones que
alcanzan el mayor \(\widehat S\) dentro de cada extractor.

\begin{table}[ht]
  \centering
  \caption{Mejores combinaciones por extractor según \(\widehat S\).}
  \label{tab:int_quality_dbscan_top}
  \begin{tabular}{lrrrrr}
    \hline
    \textbf{Extractor} & \(\boldsymbol{\varepsilon}\) &
    \texttt{min\_samp.} & \textbf{Ruido} &
    \(\widehat S\) & \(\widehat{DB}\) \\
    \hline
    VGG-16        & 0.25 & 5 & 0.99 & 0.709 & 0.997 \\
    DenseNet-121  & 0.25 & 5 & 0.97 & 0.685 & 0.925 \\
    ResNet-50     & 0.25 & 5 & 0.97 & 0.651 & 0.888 \\
    ResNet-18     & 0.45 & 5 & 0.05 & 0.614 & 0.955 \\
    \hline
  \end{tabular}
\end{table}

Se observa que:

\begin{itemize}
  \item Los extractores VGG-16, DenseNet-121 y ResNet-50 maximizan
        \(\widehat S\) con \(\varepsilon=0.25\) y
        \texttt{min\_samples}=5, pero a costa de una
        \textit{noise\_ratio} cercana al 100 \%.
  \item ResNet-18 necesita un \(\varepsilon\) mayor (0.45) para obtener
        su mejor \(\widehat S\); la consecuencia es un
        \textit{noise\_ratio} mucho menor (\(\sim\)5 \%),
        aunque la densidad de los grupos disminuye.
  \item En todos los extractores, valores intermedios de
        \(\varepsilon\approx0.30\)–0.35 equilibran cohesión y cobertura,
        pero sin sobresalir en ninguno de los indicadores.
\end{itemize}

%....................................................................
\subsubsection{Síntesis de las mejores configuraciones}
%....................................................................

Para facilitar la comparación se selecciona, por cada
\textit{extractor × algoritmo}, la ejecución con mayor media geométrica de
\((\widehat S,\widehat{DB},\widehat{CH})\).
La Tabla~\ref{tab:int_quality_best} resume dichos “ganadores”.

\begin{table}[!h]
  \centering
  \caption{Resumen de las mejores configuraciones por extractor y algoritmo, usando la media geométrica de los tres índices normalizados como criterio global.}
  \label{tab:int_quality_best}
  \begin{tabular}{llccc}
    \hline
    \textbf{Extractor} & \textbf{Algoritmo} & \textbf{Silhouette} & \textbf{Davies–Bouldin} & \textbf{Calinski–Harabasz} \\ \hline
    DenseNet-121 & K–Means        & 0.553 & 0.182 & 0.905 \\
                 & Agglomerative  & 0.544 & 0.109 & 0.738 \\
                 & Spectral       & 0.549 & 0.175 & 0.818 \\
                 & DBSCAN         & 0.685 & 0.915 & 0.037 \\ \hline
    ResNet-18    & K–Means        & 0.557 & 0.132 & 0.787 \\
                 & Agglomerative  & 0.560 & 0.122 & 0.636 \\
                 & Spectral       & 0.546 & 0.000 & 0.682 \\
                 & DBSCAN         & 0.614 & 0.951 & 0.000 \\ \hline
    ResNet-50    & K–Means        & 0.559 & 0.221 & 1.000 \\
                 & Agglomerative  & 0.548 & 0.045 & 0.720 \\
                 & Spectral       & 0.544 & 0.068 & 0.710 \\
                 & DBSCAN         & 0.651 & 0.872 & 0.019 \\ \hline
    VGG-16       & K–Means        & 0.559 & 0.229 & 0.990 \\
                 & Agglomerative  & 0.552 & 0.163 & 0.870 \\
                 & Spectral       & 0.556 & 0.219 & 0.951 \\
                 & DBSCAN         & 0.709 & 1.000 & 0.061 \\ \hline
  \end{tabular}
\end{table}

\begin{enumerate}
  \item \textbf{ResNet-50 + K–Means} resulta la combinación más consistente al maximizar simultáneamente los tres índices.
  \item \textbf{DenseNet-121 + K–Means} y \textbf{DenseNet-121 + Spectral} muestran un rendimiento muy similar, confirmando que características densas extraídas de capas profundas favorecen la separabilidad interna.
  \item \textbf{DBSCAN} sobresale solo en \(\widehat{DB}\); su aplicabilidad queda restringida a casos donde la detección de “núcleos” densos sea prioritaria sobre cubrir la totalidad del corpus.
\end{enumerate}

En conjunto, los resultados preliminares indican que la elección del \emph{extractor} incide más sobre la calidad interna que la selección del \emph{algoritmo}.
Las configuraciones basadas en ResNet-50 y DenseNet-121 se mantendrán como candidatas para las comparaciones externas con la clasificación arqueológica.

%....................................................................
\subsubsection{Visualización t-SNE de las configuraciones ganadoras}
%....................................................................

Con el $k^\ast$ seleccionado, se proyectaron los embeddings de motivos
mediante t-SNE (perplejidad = 30, 1\,000 iteraciones) para las tres
configuraciones de mayor desempeño global
(ResNet-50 + K–Means, DenseNet-121 + K–Means, DenseNet-121 + Spectral).
Las Figuras~\ref{fig:tsne_resnet50_kmeans}–\ref{fig:tsne_dense_spectral}
ilustran la separabilidad visual de los grupos.

\begin{figure}[!h]
  \centering
  % ----------- t-SNE plots -----------
  \subfloat[ResNet-50 + K--Means ($k=4$)\label{fig:tsne_resnet50_kmeans}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_resnet50_kmeans_k4}}\hfill
  \subfloat[DenseNet-121 + K--Means ($k=4$)\label{fig:tsne_dense_kmeans}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_densenet121_kmeans_k4}}\hfill
  \subfloat[DenseNet-121 + Spectral ($k=4$)\label{fig:tsne_dense_spectral}]{%
    \includegraphics[width=.31\textwidth]{Images/tsne_densenet121_spectral_k4}}

  %----- caption + label -----
  \caption{Proyección t-SNE de las configuraciones con mayor media
    geométrica de los índices internos. Cada color representa un grupo;
    la separación espacial respalda la coherencia semántica discutida.}%
  \label{fig:tsne_best}
\end{figure}

\vspace{1ex}
\paragraph{DBSCAN y gráficas de Silhouette.}
Para DBSCAN las curvas de Silhouette frente a \(\varepsilon\) se relegan al
Apéndice~B: ilustran que la calidad interna mejora hasta
\(\varepsilon\approx0.35\) antes de diluirse por exceso de ruido.
Dado que DBSCAN no optimiza $k$, estas gráficas se usan solo como referencia
de densidad y no influyen en la selección final de configuraciones.

\subsection{Distribución de Motivos por Grupo}

Antes de analizar el contenido de cada conglomerado se examinó la cantidad de imágenes que cayó en cada uno.
La Tabla~\ref{tab:cluster_sizes} muestra el número de motivos por grupo para las mismas tres configuraciones.

\begin{table}[!h]
  \centering
  \begin{tabular}{lccc}
    \hline
    Grupo & \texttt{densenet121\_kmeans} & \texttt{densenet121\_spectral} & \texttt{resnet50\_kmeans}\\
    \hline
    0 & 2\,250 & 4\,634 & 2\,012\\
    1 & 2\,065 & 2\,667 & 1\,674\\
    2 & 1\,153 & 19     & 1\,532\\
    3 & 2\,036 & 184    & 2\,285\\
    \hline
  \end{tabular}
  \caption{Número de motivos asignados a cada grupo.  La desproporción extrema en el grupo 2 de \texttt{densenet121\_spectral\_k4} obedece a la separación de un motivo atípico (véase Sección~\ref{ssec:analisis_cualitativo}).}
  \label{tab:cluster_sizes}
\end{table}

La distribución revela dos aspectos clave.
Primero, la configuración \texttt{densenet121\_spectral\_k4} concentra casi el 60 \% de sus imágenes en el grupo 0, mientras que su grupo 2 se reduce a apenas 19 ejemplos.
Este reparto extremo sugiere que el algoritmo espectral, combinado con las características extraídas por \texttt{densenet121}, identificó un subconjunto muy específico (una única escena de guanaco con superposición de mano en diferentes iluminaciones) y lo aisló casi por completo.
Segundo, los métodos basados en \texttt{k}-means muestran particiones más equilibradas, aunque mantienen un ligero predominio de los grupos que agrupan tonalidades amarillas y anaranjadas (grupos 0 y 3, respectivamente).

\subsection{Análisis Cualitativo Guiado por la Especialista}
\label{ssec:analisis_cualitativo}

La arqueóloga examinó dos subconjuntos:
(i) una selección dirigida de 100 imágenes curadas y
(ii) un muestreo aleatorio de 20 imágenes por grupo.

Los tres algoritmos, pese a sus diferencias en $H$ y $C$, convergen en un mismo sesgo: agrupan principalmente según la \emph{temperatura de color} y las condiciones de iluminación, no por la morfología de los motivos.
Así, los grupos dominados por tonos amarillos reúnen con frecuencia guanacos clasificados arqueológicamente como estilo A1, mientras que las escenas con fondos grisáceos concentran ejemplares estilo A2, junto con algunas figuras estilizadas de clase A5.

En \texttt{densenet121\_kmeans\_k4}, el grupo 2 reúne imágenes de contraste tenue y composición alargada, sin un tema zoomórfico claramente dominante.
Contrasta con los grupos 0 y 3, coherentes en cromática amarillo–roja respectiva.
La versión espectral con \texttt{densenet121} va más lejos: el mismo guanaco, superpuesto con una mano pintada y captado bajo iluminaciones diversas, se aísla casi en exclusividad dentro del grupo 2 (19 imágenes).
\texttt{resnet50\_kmeans\_k4} reproduce la separación cromática en bandas (amarillo, cálido anaranjado, gris azulado) y, en la selección curada, marca una distinción algo más nítida entre estilos A y B.
Sin embargo, esa separación se diluye al observar el muestreo aleatorio.

Un experimento adicional consistió en forzar el número de grupos a ocho, el mismo que emplea la tipología estilística vigente.
Con \texttt{resnet50\_kmeans\_k8} observamos que los guanacos de estilo~A1 se agrupan aún con mayor pureza: el \textbf{grupo 5} concentra más del 90 \% de las imágenes etiquetadas como A1 en la selección curada y muestra una coherencia cromática y morfológica superior a la vista en los modelos con $k=4$.
La Fig.~\ref{fig:r50k8_cluster5} ilustra ese conglomerado.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.8\linewidth]{Images/resnet50_kmeans8_cluster5_collage}
  \caption{Collage de 20 miniaturas del \textbf{grupo 5} generado por \texttt{resnet50\_kmeans\_k8}.
  Predominan guanacos de estilo~A1, lo que sugiere que aumentar el número de grupos favorece la separación fina de este estilo.}
  \label{fig:r50k8_cluster5}
\end{figure}

La Fig.~\ref{fig:cluster_collages} ilustra, mediante collages de 20 miniaturas, los cuatro grupos generados por \texttt{densenet121\_spectral\_k4}.
La fuerte coherencia tonal salta a la vista, al tiempo que la diversidad morfológica dentro de cada collage confirma el predominio del color como factor de agrupación.

\begin{figure}[!h]
  \centering
  \includegraphics[width=\linewidth]{Images/densenet121_spectral_collage}
  \caption{Collages ilustrativos de los cuatro grupos generados con \texttt{densenet121\_spectral\_k4}.
  Cada collage agrupa 20 imágenes seleccionadas aleatoriamente dentro del grupo.}
  \label{fig:cluster_collages}
\end{figure}

En síntesis, las métricas numéricas coinciden con la valoración experta al señalar que las configuraciones basadas en \texttt{densenet121} producen los conglomerados más “coherentes” en términos de color, aunque esa coherencia no siempre se traduce en agrupaciones semánticamente significativas para la tipología arqueológica.
