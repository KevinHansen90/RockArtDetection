\chapter{Materiales y Métodos}

A continuación se describe la metodología empleada en el estudio, detallando los materiales y procedimientos que permiten analizar y clasificar las representaciones de arte rupestre presentes en las imágenes seleccionadas.
Primero, se expone el proceso de selección y clasificación de imágenes, considerando la diversidad iconográfica y las condiciones de captura de las mismas.
Seguidamente, se presenta la división automática de las imágenes en sub-regiones que facilitan la tarea de detección y el empleo de técnicas de preprocesamiento, diseñadas para mejorar la visibilidad de elementos complejos o de bajo contraste.
Se incluye una selección de modelos de detección preentrenados y se describe el proceso experimental implementado para evaluar su rendimiento.
Finalmente, se detallan los métodos de agrupamiento aplicados para la organización de elementos identificados, junto con una discusión de los resultados preliminares, las métricas evaluadas y las conclusiones de las técnicas y modelos que mejor se adaptan a la problemática de detección en arte rupestre.


\noindent
Todo el código empleado, pipelines de detección, algoritmos de agrupamiento no supervisado y utilidades de preprocesamiento, está disponible en el repositorio público
\href{https://github.com/KevinHansen90/RockArtDetection}{\texttt{github.com/KevinHansen90/RockArtDetection}}, cuyo \texttt{README.md} resume los pasos descritos a lo largo de este capítulo y enlaza a los programas correspondientes.

\section{Preparación del Conjunto de Datos}

Se realizan cuatro etapas distintas que aseguran trazabilidad desde la captura hasta los recortes finales empleados para entrenar los detectores y algoritmos no supervisados.
El material original utilizado se publica en un repositorio de acceso abierto\footnote{\href{https://drive.google.com/drive/u/0/folders/1JU5tohaRw7Rm83S9uUK9KazIPLRebl1x}{Google Drive Dataset}.
El directorio incluye un archivo \texttt{README} con instrucciones para descargar, verificar y recrear la estructura de carpetas.}.
Las siguientes subsecciones profundizan en cada fase y documentan las decisiones técnicas adoptadas.

\subsection{Selección de Imágenes}
Se seleccionan un total de 683 fotografías con una resolución de \(4.288 \times 2.848\ \text{px}\) píxeles, capturadas entre los años 2019 y 2023 en los aleros de Cueva de las Manos, ubicada en la zona de Río Pinturas, Santa Cruz, Argentina.
Estas imágenes son tomadas por el equipo de arqueólogos que trabajan en el sitio y pertenecen al Instituto Nacional de Antropología y Pensamiento Latinoamericano (INAPL).
Se trabaja en estrecha colaboración con la Lic. Agustina Papú, una arqueóloga especializada en Arte Rupestre, quien asiste en la selección y etiquetado de las imágenes.

La metodología para la selección de las imágenes busca cubrir la totalidad de los paneles presentes en los aleros, asegurando la repetición de capturas en aquellas zonas donde se consiguen diferentes ángulos o condiciones lumínicas.
Esta estrategia permite obtener una representación más completa de los elementos presentes en el sitio.

En la Figura~\ref{fig:imagen_ejemplo} se muestra un ejemplo de las imágenes seleccionadas. Esta imagen contiene un total de 17 elementos, donde se observa la presencia de superposiciones, una característica común en el arte rupestre de la zona.
La diferenciación de algunos de estos elementos respecto del fondo presenta dificultades, dadas las similitudes cromáticas y la erosión natural que ha sufrido la superficie rocosa a lo largo del tiempo.
Estas condiciones complican el reconocimiento automatizado del arte rupestre.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Images/imagen_ejemplo}
    \caption{Ejemplo de una imagen seleccionada para el estudio.}
    \label{fig:imagen_ejemplo}
\end{figure}

\subsection{Clasificación y Etiquetado Inicial}

En el sitio arqueológico de Cueva de las Manos se encuentran imágenes que varían considerablemente en su grado de abstracción, abarcando desde representaciones detalladas de animales y figuras humanas hasta elementos geométricos más simples.
Esta diversidad iconográfica refleja la riqueza del arte rupestre de la región, cubriendo tanto aspectos figurativos como abstractos.

Con el objetivo de llevar a cabo un análisis detallado y sistemático, se propone una clasificación inicial de las imágenes, que comprende un total de 19 clases distintas, basada en los conocimientos de la licenciada Agustina Papú.
Las clases iniciales propuestas son las siguientes:

\begin{table}[!h]
    \centering
    \begin{tabular}{r l}
        \hline
        \textbf{ID} & \textbf{Clase} \\
        \hline
        0  & Zoomorfo (artiodactyla) \\
        1  & Zoomorfo (ave) \\
        2  & Zoomorfo (piche) \\
        3  & Zoomorfo (matuasto) \\
        4  & Antropomorfo \\
        5  & Positivo de mano \\
        6  & Negativo de mano \\
        7  & Negativo de pata de choique \\
        8  & Negativo de puño \\
        9  & Círculos \\
        10 & Círculos concéntricos \\
        11 & Líneas rectas \\
        12 & Líneas zigzag \\
        13 & Escala \\
        14 & Persona \\
        15 & Lazo bola \\
        16 & Conjuntos de puntos \\
        17 & Impactos \\
        18 & Tridígitos \\
    \end{tabular}
    \caption{Clases de motivos pictográficos y su identificador numérico.}
    \label{tab:clases-motivos}
\end{table}

La herramienta makesense.ai ~\cite{makesense} se utiliza para el etiquetado de las imágenes, elegida por su facilidad de uso y la capacidad de trabajar con lotes de tamaño personalizado.
Esta flexibilidad permite adaptarse a la disponibilidad de la arqueóloga, optimizando así el proceso de etiquetado.
A lo largo de un mes, se lleva a cabo el etiquetado de las imágenes utilizando la clasificación inicial mencionada, lo que facilita no sólo la organización de los datos, sino también un análisis más profundo de las representaciones iconográficas presentes en el sitio.
Se presenta un resumen de las cantidades de elementos etiquetados por cada categoría en la tabla~\ref{tab:conteo_porcentajes}.

\begin{table}[!h]
    \centering
    \begin{tabular}{l r r}
        \hline
        \textbf{Clase} & \textbf{Elementos} & \textbf{Porcentaje} \\
        \hline
        Zoomorfo (artiodactyla)      & 7\,374 & 51\% \\
        Zoomorfo (ave)               &    82 &  1\% \\
        Zoomorfo (piche)             &     0 &  0\% \\
        Zoomorfo (matuasto)          &    48 &  0\% \\
        Antropomorfo                 & 1\,434 & 10\% \\
        Positivo de mano             &    31 &  0\% \\
        Negativo de mano             & 4\,189 & 29\% \\
        Negativo de pata de choique  &    27 &  0\% \\
        Negativo de puño             &    13 &  0\% \\
        Círculos                     &    80 &  1\% \\
        Círculos concéntricos        &    29 &  0\% \\
        Líneas rectas                &    67 &  0\% \\
        Líneas zigzag                &    42 &  0\% \\
        Escala                       &   202 &  1\% \\
        Persona                      &     6 &  0\% \\
        Lazo bola                    &    43 &  0\% \\
        Conjuntos de puntos          &   324 &  2\% \\
        Impactos                     &   441 &  3\% \\
        Tridígitos                   &    15 &  0\% \\
        \hline
        \textbf{Totales}             & \textbf{14\,447} & \textbf{100\%} \\
    \end{tabular}
    \caption{Distribución de motivos, recuentos y porcentajes en el conjunto de datos de arte rupestre.}
    \label{tab:conteo_porcentajes}
\end{table}

En la Figura~\ref{fig:imagen_etiquetada} se presenta un ejemplo de una de las imágenes etiquetadas según esta clasificación inicial.
Esta figura ilustra cómo las diferentes clases se aplican a los elementos identificados en la imagen, proporcionando una visualización clara del proceso de etiquetado.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Images/imagen_etiquetada}
    \caption{Imagen etiquetada con la clasificación inicial propuesta.}
    \label{fig:imagen_etiquetada}
\end{figure}

La distribución original de las diecinueve clases exhibe un desequilibrio pronunciado: la clase ``Zoomorfo (artiodactyla)'' reúne \textbf{7\,374} instancias, mientras que ``Persona'' aporta solamente seis.
Para mitigar el sesgo que esta diferencia introduce durante el entrenamiento, las clases finas se agrupan en seis categorías semánticas más amplias.
Los cuatro motivos zoomórficos con identificadores de 0 a 3 se integran en la categoría \textit{Animal}.
El motivo \textit{Antropomorfo}, identificador 4, se incorpora a \textit{Human}.
Las impresiones de mano, ``Positivo de mano'', ``Negativo de mano'' y ``Negativo de puño'', identificadores 5, 6 y 8, conforman la categoría \textit{Hand}.
Las huellas de animales, ``Negativo de pata de choique'' y ``Tridígitos'', identificadores 7 y 18, se agrupan en \textit{Animal\_print}.
Los motivos geométricos, ``Círculos'', ``Círculos concéntricos'', ``Líneas rectas'', ``Líneas zigzag'', ``Lazo bola'', ``Conjuntos de puntos'' e ``Impactos'', identificadores de 9 a 12 y de 15 a 17, conforman la categoría \textit{Geometric}.
Por último, ``Escala'' y ``Persona'', identificadores 13 y 14, se integran en la categoría \textit{Other}.
La Tabla~\ref{tab:grupos} resume la nueva distribución de frecuencias y porcentajes y evidencia la reducción del desbalance inicial.

\begin{table}[!h]
    \centering
    \begin{tabular}{l r r}
        \hline
        \textbf{Categoría agrupada} & \textbf{Elementos} & \textbf{Porcentaje} \\
        \hline
        Animal        & 7.504 & 52\,\%  \\
        Hand          & 4.233 & 29\,\%  \\
        Human         & 1.434 & 10\,\%  \\
        Animal\_print &    42 & 0,3\,\% \\
        Geometric     & 1.026 & 7\,\%   \\
        Other         &   208 & 1\,\%   \\
        \hline
        \textbf{Total} & \textbf{14.447} & \textbf{100\,\%} \\
    \end{tabular}
    \caption{Frecuencias y porcentajes tras agrupar las 19 clases originales en 6 categorías amplias.}
    \label{tab:grupos}
\end{table}

Dada la importancia arqueológica y la preponderancia de manos y animales en el sitio en estudio, se seleccionan como elementos de estudio para los entrenamientos únicamente las clases de \textit{Animal} y \textit{Hand}.

\subsection{División Automática de Imágenes}

Dada la gran cantidad de elementos presentes en cada imagen y la dificultad inherente en la detección de objetos, se decide dividir las imágenes automáticamente en cuadrados de 512x512 píxeles, tamaño estándar utilizado en la mayoría de los modelos de detección de objetos.
Esta división se realiza manteniendo los objetos etiquetados originalmente, pero agregando una superposición de \textbf{10\%} entre las nuevas imágenes fraccionadas, permitiendo a los modelos aprender mejor el contexto de cada objeto.
Además, se descartan aquellos cuadrados en los que no se identifica ninguna parte relevante de las etiquetas. Esta división resulta en \textbf{32\,538} imágenes, con \textbf{64\,913} objetos: \textbf{46\,348} para \textit{Animal} y \textbf{18\,565} para \textit{Hand}.
La proporción entre clases se mantiene de forma aproximada, siendo las diferencias explicadas por un distintos solapamiento dependiendo del tamaño y posición del objeto original.

En la Figura~\ref{fig:imagen_dividida} se muestran cinco recortes de 512x512 píxeles obtenidos a partir de la imagen original.
Cada clase identificada en los recortes está representada por un color específico, lo cual facilita la visualización de los distintos elementos en el arte rupestre.

\begin{figure}[!h]
    \centering
    \begin{minipage}{0.19\textwidth}
        \includegraphics[width=\textwidth]{Images/recorte1}
    \end{minipage}
     \hfill
     \begin{minipage}{0.19\textwidth}
        \includegraphics[width=\textwidth]{Images/recorte2}
     \end{minipage}
    \hfill
     \begin{minipage}{0.19\textwidth}
        \includegraphics[width=\textwidth]{Images/recorte3}
     \end{minipage}
     \hfill
     \begin{minipage}{0.19\textwidth}
         \includegraphics[width=\textwidth]{Images/recorte4}
     \end{minipage}
     \hfill
    \begin{minipage}{0.19\textwidth}
         \includegraphics[width=\textwidth]{Images/recorte5}
     \end{minipage}
     \caption{Recortes de 512x512 píxeles obtenidos de la imagen original.}
     \label{fig:imagen_dividida}
\end{figure}

\subsection{Extracción de Motivos para Análisis No Supervisado}

Para que los algoritmos de agrupamiento trabajen exclusivamente sobre la información pictográfica se genera, a partir de cada fotografía anotada, un banco de recortes unitarios.
El procedimiento automatizado recorre la carpeta de imágenes originales y su correspondiente directorio de etiquetas en formato YOLO, lee cada línea de la etiqueta y convierte las coordenadas normalizadas a coordenadas absolutas en píxeles, es decir, relativas al tamaño real de cada imagen.
Con estas coordenadas se recorta el motivo y, se redimensiona preservando la relación de aspecto y aplicando remuestreo Lanczos cuando el lado mayor debe igualar \(224\,\text{px}\).
El recorte resultante se guarda con un nombre que codifica la imagen fuente, la clase y un índice secuencial.
Un reporte final informa del número total de motivos extraídos y del porcentaje de etiquetas válidas procesadas.

El trabajo se centra en la clase \textit{Animal}, que aporta 7\,504 recortes a partir de las imágenes en crudo.
Esta decisión responde a dos razones: en primer lugar, los animales constituyen la categoría más frecuente y, en segundo lugar, sus variantes morfológicas permiten evaluar si los grupos reflejan o no las distinciones que la arqueología actual reconoce entre subtipos zoomórficos.

La Figura~\ref{fig:crop_example} muestra tres ejemplos de recortes generados.
Se observa que aunque el ruido del fondo se minimice, el de superposición sigue presente.

Trabajar con imágenes aisladas de esta forma reduce el ruido de fondo, homogeneiza la escala y facilita la comparación de texturas, contornos y cromatismos.
Además incrementa el tamaño efectivo del conjunto de datos, lo que mejora la densidad de muestras y, por extensión, la robustez de técnicas como \emph{k}-means.

\begin{figure}[!h]
    \centering
    \includegraphics[width=.3\textwidth]{Images/crop_example1}\hfill
    \includegraphics[width=.3\textwidth]{Images/crop_example2}\hfill
    \includegraphics[width=.3\textwidth]{Images/crop_example3}
    \caption{Ejemplos de recortes individuales pertenecientes a la clase \textit{Animal}.}
    \label{fig:crop_example}
\end{figure}

\section{Detección Supervisada de Motivos}

La detección automática se aborda como un problema supervisado: dado un recorte de \(512\times512\,\text{px}\) cada combinación de modelo y técnica de preprocesamiento debe localizar y clasificar los motivos visibles.
Ademas, se puede aplicar el modelo entrenado para potencialmente detectar motivos que no han sido etiquetados, o fueron omitidos por la Licenciada Papú.
En cada una de las subsiguientes secciones, se detallan las decisiones técnicas que conforman el proceso de entrenamiento.

\subsection{Técnicas de Preprocesamiento}

El preprocesamiento de imágenes suele ser un paso crucial antes de aplicar algoritmos de detección o clasificación en arte rupestre.
Debido a la baja visibilidad y al deterioro de los motivos, es indispensable mejorar la calidad y el contraste de las fotografías para facilitar la tarea de los modelos (y de los propios investigadores)~\cite{li2022}.
A continuación, se presentan cuatro técnicas de preprocesamiento que han demostrado su utilidad en escenarios de bajo contraste o con ruido elevado, no sólo en arte rupestre sino también en otros dominios (imágenes médicas, fotografía subacuática, etc.):

\begin{itemize}
\item \textbf{CLAHE} (Contrast Limited Adaptive Histogram Equalization): Realza el contraste de forma localizada sin amplificar excesivamente el ruido.
\item \textbf{Filtrado Bilateral} (\textit{Bilateral Filtering}): Suaviza la imagen conservando los bordes importantes.
\item \textbf{Máscara de Realce} (\textit{Unsharp Masking}): Realza los contornos al intensificar el contraste de los bordes.
\item \textbf{Pirámides Laplacianas}: Abordan el realce de detalles y bordes a múltiples escalas.
\end{itemize}

Estas técnicas pueden aplicarse de manera individual o encadenarse en secuencias concretas (por ejemplo, primero CLAHE para potenciar el contraste local y después un filtrado bilateral para reducir ruido), adaptándose a las necesidades de cada imagen.
Diversos flujos de trabajo en arte rupestre aplican procesos similares, como convertir a escala de grises, aplicar CLAHE y luego un filtrado bilateral, para posteriormente, proceder a la clasificación manual o automatizada~\cite{xiao2020,li2022}.

\subsubsection{CLAHE (Contrast Limited Adaptive Histogram Equalization)}

\textit{CLAHE} constituye una variante de la ecualización de histograma que actúa de forma local y limita la amplificación excesiva del contraste en cada región de la imagen.
El procedimiento divide la imagen en pequeñas “baldosas” (\textit{tiles}), a las cuales aplica ecualización de histograma con un umbral de corte (\textit{clip limit}) que impide la sobresaturación~\cite{xiao2020}.
Esto resulta especialmente beneficioso en imágenes con iluminación desigual o bajo contraste global, comunes en arte rupestre, ya que puede realzar detalles en zonas oscuras o descoloridas sin afectar drásticamente el resto de la fotografía.
En contextos de arte rupestre, donde los motivos pueden ocupar áreas muy específicas (por ejemplo, un dibujo de mano en ocre rojo sobre una pared rocosa), el ajuste local que ofrece CLAHE logra enfatizar mejor los contornos y colores que podrían pasar desapercibidos con un ajuste global.
Xiao \textit{et al.} (2020) reportan mejoras significativas al emplear CLAHE para segmentar fragmentos de mineral en cintas transportadoras de bajo contraste, mostrando que el método realza detalles sutiles y reduce el ruido de fondo~\cite{xiao2020}.
Esta misma lógica se aplica al arte rupestre: al potenciar localmente el área pintada, se facilita la distinción entre el pigmento y la textura natural de la roca.

\subsubsection{Filtrado Bilateral (\textit{Bilateral Filtering})}

El filtrado bilateral es un método de suavizado que conserva bordes al combinar información de proximidad espacial y similitud de intensidad~\cite{paris2008,sidorenko2021}.
A diferencia de los filtros de desenfoque tradicionales, que promedian todos los píxeles de una ventana, el filtrado bilateral evita mezclar valores de píxel en regiones con transiciones bruscas de intensidad, manteniendo así la nitidez de los contornos.
En imágenes de arte rupestre, esta propiedad permite reducir la textura granular de la piedra (fisuras, o ruido del sensor) sin difuminar las líneas que conforman el motivo~\cite{xiao2020}.
Resulta habitual ver estudios en los que se combina un paso de realce de contraste (por ejemplo, CLAHE) seguido de filtrado bilateral para atenuar el ruido residual y resaltar los contornos de las pinturas o grabados~\cite{li2022}.
Sidorenko~\textit{et~al.} (2021) emplean imágenes filtradas bilateralmente como referencia supervisada para entrenar una red que aprenda a \emph{suavizar} superficies digitalizadas sin pérdida de bordes discernibles~\cite{sidorenko2021}, reforzando así el filtrado bilateral como un estándar de reducción de ruido con preservación de detalles.

\subsubsection{Máscara de realce (\textit{Unsharp Masking})}

La \textit{unsharp masking} es una técnica clásica de acentuación de bordes, heredada de la fotografía analógica y popularizada en editores como Photoshop~\cite{adobe_unsharp_masking}.
El procedimiento crea una \emph{copia suavizada} (mediante un filtro gaussiano) de la imagen original.
Esta copia se resta de la imagen nítida para aislar los componentes de alta frecuencia (bordes y detalles finos).
Dicho realce se suma de nuevo, ponderado por un factor de ganancia, de modo que la imagen final se percibe más definida sin introducir desenfoque global.

En fotografía de arte rupestre, esta operación puede marcar la diferencia entre ignorar un motivo tenue y visualizarlo con la nitidez suficiente para su trazado~\cite{xiao2020}.
No “recupera” información perdida, pero incrementa el contraste local, haciendo más visibles los límites de pigmentos o grabados.
El principal cuidado es evitar valores excesivos de radio o ganancia.
Un realce desmedido provoca \emph{halos} que pueden confundirse con trazos auténticos~\cite{adobe_unsharp_masking}.


\subsubsection{Pirámides Laplacianas para Realce Multiescala}

La pirámide Laplaciana es una representación multi-escala de la imagen propuesta por Burt y Adelson, que se construye a partir de una pirámide Gaussiana y calcula las diferencias entre cada nivel consecutivo~\cite{bai2023,zhou2019}.
Este enfoque descompone la imagen en distintos rangos de frecuencias, permitiendo manipular, de manera diferenciada, tanto los detalles finos como las estructuras de mayor tamaño.
En la práctica, se puede enfatizar la capa que contiene los detalles intermedios, donde a menudo se ubican los contornos de figuras rupestres, y atenuar otras escalas que corresponden al ruido o a variaciones de iluminación a gran escala~\cite{paris2008}.
Esta estrategia otorga una ventaja significativa frente a filtros de realce de bordes de única escala (como la máscara de realce), ya que ofrece un control más preciso sobre cada nivel de detalle.
Aunque en el campo del arte rupestre no abunden publicaciones que mencionen explícitamente las pirámides Laplacianas, muchas técnicas de \textit{image fusion} y de \textit{Reflectance Transformation Imaging} (\textit{RTI}) aplican procesos conceptualmente similares para fusionar o realzar características visibles a diferentes distancias~\cite{zhou2019}.
La principal desventaja de este método radica en su complejidad, pues exige un mayor número de parámetros y pasos de procesamiento que las técnicas anteriores.
No obstante, su capacidad de manejar simultáneamente realces en múltiples escalas puede ser decisiva para imágenes con motivos de distintos tamaños y diferentes grados de desgaste.

\subsubsection*{Conclusión sobre el Preprocesamiento}

La elección e implementación de una u otra técnica de preprocesamiento responde al tipo de degradación que presente el arte rupestre (desgaste por erosión, superposición, iluminación irregular, etc.), y a los objetivos del análisis posterior (detección de contornos, segmentación, clasificación, etc.).
\textit{CLAHE} sobresale por su eficacia al realzar el contraste local, el \textit{filtrado bilateral} por preservar los bordes mientras reduce el ruido, la máscara de realce por intensificar contornos sutiles y las \textit{pirámides Laplacianas} por su control fino en diversas escalas.
En la práctica, es común combinar más de una estrategia para lograr un equilibrio óptimo entre la atenuación del ruido y la conservación de los rasgos esenciales de las pinturas o grabados rupestres~\cite{xiao2020,li2022}.

\subsection{Técnicas de Preprocesamiento Evaluadas}
\label{sec:preproc}
Se seleccionan distintas técnicas de preprocesamiento con el objetivo de resaltar contrastes y mejorar la detección de objetos.
Se trabaja en conjunto con la arqueóloga para emular técnicas que obtengan resultados similares a los filtros que se utilizan en la actualidad con DStretch.
Además, la selección de técnicas se basan en su efectividad en escenarios similares, como la detección de objetos camuflados en entornos complejos.
Las técnicas seleccionadas son:

\begin{itemize}
    \item \textbf{Ecualización de Histograma (CLAHE):}
    La técnica de Ecualización de Histograma Adaptativa con Limitación de Contraste (CLAHE) fue introducida para mejorar el contraste local en las imágenes, siendo especialmente útil en áreas con iluminación desigual o bajo contraste, como el arte rupestre.
    El método CLAHE, limita la amplificación de contraste para evitar la sobreexposición en áreas claras u oscuras, manteniendo los detalles en las zonas intermedias~\cite{zuiderveld1994contrast}.
    Este método ha demostrado ser particularmente efectivo para resaltar diferencias sutiles entre el fondo y los elementos pictográficos.

    \item \textbf{Filtro Bilateral:}
    Propuesto por Tomasi y Manduchi~\cite{tomasi1998bilateral}, el filtro bilateral suaviza la imagen mientras preserva los bordes, ideal para contextos donde es necesario reducir el ruido sin perder detalles importantes.
    En el arte rupestre, donde la textura y el detalle son esenciales, este filtro ayuda a mejorar la visibilidad de los elementos, preservando las características clave de bordes.

    \item \textbf{Filtro Gaussiano:}
    Este filtro, ampliamente estudiado en el procesamiento de imágenes, reduce el ruido mediante la aplicación de una convolución con un núcleo gaussiano, suavizando las imágenes mediante un promedio ponderado de los píxeles vecinos.
    Al ser menos susceptible a ruidos aleatorios, ayuda a eliminar imperfecciones sin perder la estructura general de los elementos pictográficos~\cite{gonzalesWood}.

    \item \textbf{Pirámide Laplaciana:}
    Introducida por Burt y Adelson~\cite{burt1983laplacian}, la pirámide laplaciana permite representar la imagen en diferentes niveles de detalle.
    Esta técnica es ideal para analizar elementos grandes y pequeños en imágenes complejas, como las de arte rupestre, donde se necesita visualizar tanto detalles finos como formas generales para una adecuada identificación.
\end{itemize}

La aplicación de estas técnicas a las imágenes seleccionadas busca mejorar la calidad de la detección de objetos en las pinturas rupestres.
Al resaltar contrastes, reducir ruido y enfocar las características clave, se espera que estas técnicas permitan una detección más precisa y efectiva de los elementos presentes en el arte rupestre de la Cueva de las Manos.
Se comparan las distintas técnicas empleadas contra un escenario base sin procesamiento.

\subsection{Métricas de Evaluación}

El rendimiento de cada modelo se valora mediante cuatro métricas complementarias que describen tanto el proceso de optimización como la calidad final de las predicciones.

\begin{itemize}
    \item \textbf{Función de pérdida del conjunto de entrenamiento (\emph{train\_loss}):}\\[2pt]
      Se define como el promedio, lote a lote, de la suma ponderada de sus tres componentes fundamentales:
      \[
      \mathcal{L}_{\text{train}}
      =\frac{1}{B}\sum_{b=1}^{B}
        \bigl(
          \mathcal{L}_{\text{cls}}^{(b)}
          +\mathcal{L}_{\text{reg}}^{(b)}
          +\lambda\,\mathcal{L}_{\text{IoU}}^{(b)}
        \bigr)
      \]
      donde
      \begin{itemize}
        \item $\mathcal{L}_{\text{cls}}$ \,(pérdida de \textit{clasificación}, \emph{classification loss}) cuantifica el error al asignar la clase correcta a cada instancia; suele implementarse como entropía cruzada o \emph{Focal Loss}.
        \item $\mathcal{L}_{\text{reg}}$ \,(pérdida de \textit{regresión de cajas}, \emph{box regression loss}) mide la discrepancia entre las coordenadas predichas y las cajas de verdad‐terreno.
        \item $\mathcal{L}_{\text{IoU}}$ \,(pérdida de \textit{superposición IoU}, \emph{IoU-based loss}) penaliza predicciones con baja intersección-sobre-unión; $\lambda$ es su peso relativo.
      \end{itemize}
      Un descenso sostenido de $\mathcal{L}_{\text{train}}$ indica que el optimizador encuentra gradientes informativos y ajusta los parámetros al dominio de la tarea~\cite{goodfellow2016deep}.

    \item \textbf{Función de pérdida del conjunto de validación (\emph{val\_loss}):}\\[2pt]
      Se calcula con la misma expresión que la anterior, pero sobre un subconjunto independiente y sin actualizar los pesos:
      \[
      \mathcal{L}_{\text{val}}
      =\frac{1}{B_v}\sum_{b=1}^{B_v}
        \bigl(
          \mathcal{L}_{\text{cls}}^{(b)}
          +\mathcal{L}_{\text{reg}}^{(b)}
          +\lambda\,\mathcal{L}_{\text{IoU}}^{(b)}
        \bigr)
      \]
      Al comparar su evolución con $\mathcal{L}_{\text{train}}$ se detecta sobreajuste: si $\mathcal{L}_{\text{val}}$ deja de disminuir o aumenta mientras $\mathcal{L}_{\text{train}}$ continúa bajando, el modelo pierde capacidad de \emph{generalizar} a ejemplos no vistos~\cite{goodfellow2016deep}.
      Los términos $\mathcal{L}_{\text{cls}}$, $\mathcal{L}_{\text{reg}}$ y $\mathcal{L}_{\text{IoU}}$ mantienen el mismo significado descrito arriba, garantizando una comparación directa entre entrenamiento y validación.

    \item \textbf{mAP\textsubscript{0.5} (media de precisión promedio con $\text{IoU}=0.5$):}\\[2pt]
      Se obtiene promediando la \emph{precisión promedio} (\textit{Average Precision}, $\mathrm{AP}$) de cada clase $c$ cuando el criterio de acierto exige una intersección-sobre-unión $\text{IoU}\ge 0.5$:
      \[
      \text{mAP}_{0.5}
      \;=\;
      \frac{1}{C}\sum_{c=1}^{C}
      \underbrace{\int_{0}^{1} P_c(R)\,dR}_{\mathrm{AP}_c}
      \]
      donde
      \begin{itemize}
        \item $C$ es el número total de clases.
        \item $P_c(R)$ es la \textit{precisión} ($P$) interpolada de la clase $c$ como función de la \textit{recuperación} ($R$).
        \item El integral calcula el área bajo la curva $P$-vs-$R$, es decir, la $\mathrm{AP}_c$ (precisión promedio de la clase).
        \item Sólo se consideran verdaderos positivos aquellas predicciones cuya $\text{IoU}$ con la caja de verdad-terreno supera $0.5$ (umbrales de \textit{superposición}, \emph{overlap threshold}).
      \end{itemize}
      Valores altos de $\text{mAP}_{0.5}$ indican que el modelo delimita correctamente los motivos y asigna la categoría adecuada~\cite{lin2014microsoft,everingham2010pascal}.

    \item \textbf{mAR\textsubscript{100} (media de \emph{recall} promedio con 100 detecciones por imagen):}\\[2pt]
      Promedia, entre clases, la \emph{recuperación promedio} (\textit{Average Recall}, $\mathrm{AR}$) cuando se permite un máximo de $N=100$ predicciones por imagen:
      \[
      \text{mAR}_{100}
      \;=\;
      \frac{1}{C}\sum_{c=1}^{C}
      \underbrace{\frac{1}{|G_c|}
      \sum_{g\in G_c}\!
      \mathbf{1}\bigl(
          \exists\,p\le N:\,\text{IoU}(g,p)\ge 0.5
      \bigr)}_{\mathrm{AR}_{100,c}}
      \]
      donde
      \begin{itemize}
        \item $G_c$ es el conjunto de objetos de verdad-terreno (ground-truth) de la clase $c$.
        \item $\mathbf{1}(\cdot)$ es la función indicadora que vale $1$ si para el objeto $g$ existe alguna predicción $p$ (entre las $N$ más confiables) con $\text{IoU}\ge 0.5$, y $0$ en caso contrario.
        \item $\mathrm{AR}_{100,c}$ (recuperación promedio por clase) mide qué fracción de objetos se recupera correctamente bajo el límite de 100 detecciones.
      \end{itemize}
      Al ser sensible a los falsos negativos, un alto $\text{mAR}_{100}$ refleja la capacidad del modelo para no pasar por alto motivos poco contrastados u ocluidos~\cite{cocoEval2015}.
\end{itemize}

Las \textbf{funciones de pérdida} de entrenamiento y validación monitorizan la estabilidad del aprendizaje y alertan sobre posible sobreajuste, mientras que \textbf{mAP\textsubscript{0.5}} y \textbf{mAR\textsubscript{100}} valoran el rendimiento práctico del modelo en \emph{detección de motivos} (clasificación + localización).

\begin{itemize}
    \item \emph{Funciones de pérdida}: revelan si el optimizador ajusta los parámetros al dominio sin sacrificar la capacidad de generalizar, al comparar descensos paralelos entre entrenamiento y validación.
    \item \textbf{mAP\textsubscript{0.5}}: combina precisión de clasificación y precisión de localización.
    Exige que la caja predicha se solape con la caja verdadera con $\text{IoU}\ge 0.5$, midiendo así la \emph{exactitud de las cajas}.
    \item \textbf{mAR\textsubscript{100}}: calcula la proporción de motivos correctamente \emph{recuperados} cuando se permiten hasta 100 predicciones por imagen, reflejando la cobertura del modelo y su sensibilidad a los falsos negativos.
\end{itemize}

Conjuntamente, estas métricas equilibran \emph{precisión} (mAP) y \emph{cobertura} (mAR), criterios esenciales en el análisis de arte rupestre, donde abundan figuras pequeñas, de bajo contraste y frecuentemente superpuestas.


\subsection{Selección de Modelos Preentrenados}
Se seleccionan modelos preentrenados de diversas estructuras, teniendo en cuenta su eficacia en la detección de objetos pequeños y de bajo contraste, como los presentes en el arte rupestre, así como su disponibilidad como open source, compatibilidad con los recursos computacionales disponibles, y la diversidad en la literatura revisada.
Los modelos seleccionados incluyen:

\begin{itemize}
    \item \textbf{CNNs de una etapa (RetinaNet, YOLOv5):}
    RetinaNet se selecciona por su capacidad para manejar el desequilibrio de clases a través de su función de pérdida focal~\cite{lin2017focal}.
    Este enfoque es particularmente útil en problemas donde ciertos objetos pequeños, como los elementos de arte rupestre, tienden a estar subrepresentados y podrían ser ignorados.
    Además, el uso de la Red de Pirámide de Características (FPN) permite a RetinaNet detectar objetos de diferentes tamaños y en condiciones de bajo contraste, haciendo que sea una opción robusta para detección de arte rupestre con detalles finos.
    Por su parte, YOLOv5 se selecciona debido a su rapidez y eficiencia, proporcionando un balance entre precisión y velocidad~\cite{yolov5}.
    Su diseño optimizado permite realizar pruebas iterativas de manera rápida, aunque enfrenta limitaciones en contextos de bajo contraste y con objetos superpuestos, comunes en imágenes de arte rupestre.

    \item \textbf{CNNs de dos etapas (Faster R-CNN):}
    Faster R-CNN es conocida por su capacidad de detectar objetos con alta precisión gracias a su estructura de dos etapas~\cite{ren2015faster}.
    Este modelo utiliza Redes de Propuesta de Regiones (RPN) para generar posibles ubicaciones de objetos, lo que le permite enfocar sus predicciones de manera refinada, algo crucial para detectar pequeños elementos y manejar la superposición que se encuentra en el arte rupestre.
    Al combinar Faster R-CNN con FPN, se logra mejorar la detección en múltiples escalas, permitiendo capturar tanto elementos grandes como detalles pequeños con mayor precisión.

    \item \textbf{Modelos basados en transformers (Deformable DETR):}
    Deformable DETR se selecciona por sus mejoras en la detección de objetos pequeños y su capacidad para manejar escenas complejas~\cite{zhu2021}.
    A diferencia de DETR original, Deformable DETR incorpora un mecanismo de atención deformable que focaliza su atención en áreas específicas de la imagen, adaptándose a patrones irregulares como los presentes en el arte rupestre.
    Esta técnica es particularmente eficaz para trabajar con la superposición y el bajo contraste característicos de estos entornos~\cite{horn2022,suhaimi2023}.
    Además, su arquitectura end-to-end simplifica el proceso de detección, eliminando la necesidad de etapas separadas de anclaje y refinamiento, lo cual es ventajoso cuando se trabaja con objetos abstractos y difusos.
\end{itemize}

Cada modelo potencialmente tiene beneficios para el problema en cuestión.
A continuación, se describen en la tabla~\ref{tab:justificacion_modelos}:

\begin{table}[!h]
    \centering
    \begin{tabular}{p{3.5cm} p{10.8cm}}
        \hline
        \textbf{Modelo} & \textbf{Justificación para arte rupestre} \\
        \hline
        RetinaNet &
        Gestiona el desequilibrio de clases mediante \emph{focal loss}, lo que refuerza la respuesta a figuras poco frecuentes y de tamaño reducido~\cite{lin2017focal,suhaimi2023}.
        La pirámide de características multiescala capta variaciones de escala y mejora la detección en zonas de bajo contraste y contornos difusos~\cite{esri_retinanet,wunderlich2023}. \\[0.4em]

        YOLOv5 &
        Ofrece ciclos de prueba rápidos y eficientes, aspecto clave para ajustar hiperparámetros en conjuntos de datos con miles de recortes~\cite{yolov5,suhaimi2023}.
        Aunque su precisión decrece en escenas muy superpuestas, la velocidad facilita exploraciones iterativas y comparaciones controladas~\cite{li2022}. \\[0.4em]

        Faster~R-CNN + FPN &
        La red de propuestas de regiones concentra la atención en áreas candidatas y refina bordes, ventaja crucial para objetos pequeños y parcialmente solapados~\cite{ren2015faster}.
        La combinación con FPN incrementa la sensibilidad multiescala, permitiendo capturar tanto paneles completos como motivos de pocos píxeles~\cite{suhaimi2023}. \\[0.4em]

        Deformable DETR &
        El mecanismo de atención deformable dirige los pesos a fragmentos relevantes, resistiendo fondos texturizados y variaciones cromáticas leves~\cite{zhu2021,smallobjDETR}.
        Su arquitectura \emph{end-to-end} evita el uso de anclajes manuales y se adapta bien a motivos abstractos y superpuestos, habituales en las pinturas rupestres~\cite{horn2022ai}. \\
    \end{tabular}
    \caption{Criterios de selección de los modelos preentrenados frente a los desafíos del arte rupestre: superposición, bajo contraste, abundancia de objetos y motivos abstractos.}
    \label{tab:justificacion_modelos}
\end{table}

\subsection{Ajuste fino de modelos preentrenados}

El entrenamiento parte de redes previamente entrenadas, por lo que se definen dos grupos de parámetros: uno para la \emph{backbone} convolucional y otro para la \emph{head} de detección.
La \emph{backbone} actúa como extractor de características generales de las imágenes, generando mapas de activación que condensan información visual relevante a diferentes escalas.
Suele consistir en arquitecturas profundas preentrenadas en grandes conjuntos de datos como ImageNet, tales como ResNet~\cite{he2016deep}, VGG~\cite{simonyan2014very} o DenseNet~\cite{huang2017densely}.
La \emph{head}, por su parte, está especializada en tareas específicas como la clasificación de objetos y la regresión de cajas delimitadoras.
Cuando la investigación requiere congelar la \emph{backbone}, sus gradientes se deshabilitan.
En los demás casos se asigna a cada grupo una tasa de aprendizaje distinta, menor para la \emph{backbone} y mayor para la \emph{head}, con el fin de preservar características generales y, al mismo tiempo, permitir la especialización en arte rupestre.

\subsection{Optimizadores}
Distintos algoritmos de optimización fueron evaluados para minimizar la función de pérdida durante el entrenamiento.
En todos los casos se aplicó una estrategia de descenso por mini-lotes, con ajuste diferenciado de tasas de aprendizaje para la \emph{backbone} y la \emph{head}, según lo descrito en la sección anterior.

\subsection*{SGD (por sus siglas en inglés) con momento}

El descenso estocástico del gradiente (\emph{Stochastic Gradient Descent}, SGD) constituye la referencia clásica en optimización de redes neuronales.
A lo largo de este trabajo se utiliza la variante con \emph{momento}, que acumula la información de pasos anteriores y suaviza las oscilaciones, acelerando la convergencia y reduciendo la probabilidad de estancarse en mínimos locales~\cite{robbins1951stochastic,qian1999momentum}.

\paragraph{Ecuaciones de actualización.}
Para cada parámetro \(\theta\) en la iteración \(t\) se calcula:

\[
\begin{aligned}
v_t        &= \beta\, v_{t-1} \;+\; (1 - \beta)\,\nabla_{\theta_t}\mathcal{L}(\theta_t), \\
\theta_{t+1} &= \theta_t \;-\; \eta\, v_t ,
\end{aligned}
\]

donde
\begin{itemize}
  \item \(\nabla_{\theta_t}\mathcal{L}(\theta_t)\) es el gradiente estocástico de la función de pérdida \(\mathcal{L}\) respecto del parámetro \(\theta\) (estimado sobre un mini‐lote);
  \item \(v_t\) es el \emph{vector de momento} que integra las direcciones de gradiente pasadas;
  \item \(\beta\in[0,1)\) controla la contribución del histórico (valores típicos: \(0.9\)–\(0.99\));
  \item \(\eta>0\) es la tasa de aprendizaje fija.
\end{itemize}

\paragraph{Contexto de uso.}
Este optimizador se aplica sobre todo a modelos que muestran estabilidad con tasas de aprendizaje constantes y cuyos pesos han sido previamente ajustados en tareas generales de reconocimiento visual, como es el caso de las \emph{backbones} convolucionales preentrenadas en conjuntos de datos extensos (p.\,ej.\ ImageNet).
Al emplear un \(\eta\) moderado y un valor alto de \(\beta\), la dinámica resultante actúa como un filtro de promedio exponencial sobre los gradientes:
\renewcommand\labelenumi{(\alph{enumi})}
\begin{enumerate}
  \item amortigua las fluctuaciones estocásticas inherentes al muestreo por mini‐lotes,
  \item preserva la direccionalidad global aprendida previamente, y
  \item permite ajustes finos sin perturbar drásticamente los parámetros ya “bien situados” de la \emph{backbone}.
\end{enumerate}

En consecuencia, SGD con momento proporciona una línea base sólida y de bajo coste computacional para afinar redes profundas cuando se requiere estabilidad y control preciso sobre la velocidad de aprendizaje.

\subsection*{Adam}

Adam (\emph{Adaptive Moment Estimation}) ajusta de forma adaptativa la tasa de aprendizaje de cada parámetro mediante estimaciones exponencialmente suavizadas del \textbf{primer} y \textbf{segundo momento} de los gradientes~\cite{kingma2015adam}.
Sea \(g_t=\nabla_{\theta_t}\mathcal{L}(\theta_t)\) el gradiente estocástico en la iteración \(t\); entonces:

\[
\begin{aligned}
m_t      &= \beta_1\,m_{t-1} + (1-\beta_1)\,g_t &\text{(media, 1\textsuperscript{er} momento)}\\
v_t      &= \beta_2\,v_{t-1} + (1-\beta_2)\,g_t^{2} &\text{(varianza no centrada, 2\textsuperscript{do} momento)}\\[0.5em]
\hat{m}_t &= \frac{m_t}{1-\beta_1^{t}} , \qquad
\hat{v}_t = \frac{v_t}{1-\beta_2^{t}} &\text{(corrección de sesgo)}\\[0.5em]
\theta_{t+1} &= \theta_t \;-\; \eta \,\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \varepsilon},
\end{aligned}
\]

donde
\(\beta_1,\,\beta_2\in[0,1)\) controlan la “memoria” sobre la media y la varianza (valores habituales: \(0.9\) y \(0.999\));
\(\eta\) es la tasa de aprendizaje base;
\(\varepsilon\!\ll\!1\) evita divisiones por cero.

\paragraph{Interpretación práctica.}
\begin{itemize}
  \item \textbf{Gradientes ruidosos.} Un gradiente se considera “ruidoso” cuando exhibe gran \emph{varianza estocástica} entre mini-lotes, ya sea por datos escasos, clases minoritarias o alto contraste de dificultades. Adam atenúa esa varianza al ponderar la varianza histórica \(\hat{v}_t\) en el denominador.
  \item \textbf{Magnitud heterogénea.} La escala de los gradientes puede diferir significativamente entre capas; Adam normaliza cada actualización por \(\sqrt{\hat{v}_t}\), permitiendo pasos coherentes incluso en redes profundas.
\end{itemize}

\paragraph{Ámbito de uso.}
En las \emph{heads} de detección, cuyos pesos se inicializan aleatoriamente, la combinación de escalado automático (\(\beta_2\)) y corrección de sesgo garantiza una convergencia rápida y estable, aun con conjuntos de datos desbalanceados u objetos de bajo contraste que generan gradientes de amplitud irregular.
En la práctica, Adam se adopta como método de minimización versátil y eficiente para una amplia gama de funciones de pérdida. Suele constituir un punto de partida sólido antes de explorar variantes con regularización explícita, como AdamW, cuando se requiere mayor control sobre la norma de los parámetros.

\paragraph{AdamW.}

AdamW (\emph{Adam with decoupled Weight decay}) separa explícitamente la regularización \(L_2\) de la actualización basada en gradiente, evitando que la penalización de norma sea afectada por los factores adaptativos de Adam clásico~\cite{loshchilov2019adamw}.
Sea \(g_t=\nabla_{\theta_t}\mathcal{L}(\theta_t)\) el gradiente estocástico; primero se estiman los momentos como en Adam:

\[
\begin{aligned}
m_t &= \beta_1\,m_{t-1} + (1-\beta_1)\,g_t,\\
v_t &= \beta_2\,v_{t-1} + (1-\beta_2)\,g_t^{2},\\[2pt]
\hat{m}_t &= \frac{m_t}{1-\beta_1^{t}}, \qquad
\hat{v}_t = \frac{v_t}{1-\beta_2^{t}}.
\end{aligned}
\]

A continuación se aplican \emph{dos pasos} diferenciados sobre cada parámetro \(\theta\):

\[
\begin{aligned}
\text{(i) \;Adam step:} & \quad
\theta_{t+\tfrac12} = \theta_t - \eta\,\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \varepsilon}, \\[4pt]
\text{(ii) \;Decoupled weight decay:} & \quad
\theta_{t+1} = \theta_{t+\tfrac12} - \eta\,\lambda\,\theta_t,
\end{aligned}
\]

donde \(\eta\) es la tasa de aprendizaje, \(\lambda\) el coeficiente de \emph{weight decay} (típicamente \(10^{-4}\!\text{–}\!10^{-2}\)), y \(\varepsilon\!\ll\!1\) evita divisiones por cero.

\paragraph{Ventajas del desacople.}
\begin{itemize}
  \item \textbf{Regularización homogénea.} Al aplicarse sobre \(\theta_t\) en vez de sobre \(\hat{m}_t\), la penalización \(L_2\) no se ve re-escalada por los momentos adaptativos, logrando un control más uniforme de la norma de los parámetros.
  \item \textbf{Mejora de la generalización.} Resulta particularmente beneficioso en arquitecturas con normalización interna —p.\,ej.\ \emph{LayerNorm} en Deformable~DETR— donde la magnitud absoluta de los pesos impacta la estabilidad numérica.
  \item \textbf{Convergencia estable.} Mantiene bajo control los pesos heredados de la \emph{backbone} mientras permite a la \emph{head} adaptarse rápidamente a motivos abstractos y superpuestos del arte rupestre.
\end{itemize}

En nuestras pruebas piloto, AdamW acelera la estabilización de la función de pérdida cuando la \emph{backbone} permanece activa, mostrando menor oscilación que Adam y mejor rendimiento final que SGD con momento en conjuntos de datos desbalanceados.

\begin{table}[!h]
    \centering
    \begin{tabular}{p{3.2cm} p{10.5cm}}
        \hline
        \textbf{Optimizador} & \textbf{Justificación en contexto de arte rupestre} \\
        \hline
        SGD con momento &
        Proporciona actualizaciones estables incluso con tasas de aprendizaje fijas y bajo consumo de memoria~\cite{robbins1951stochastic,qian1999momentum}.
        Ha demostrado escalar bien a lotes grandes sin degradar la precisión~\cite{goyal2017}, ventaja clave cuando se procesan miles de recortes.
        Favorece la preservación de rasgos genéricos de la \emph{backbone} y ralentiza el sobreajuste cuando los ejemplos positivos son escasos, comportamiento observado en tareas de detección rupestre~\cite{suhaimi2023}. \\[0.3em]

        Adam &
        Ajusta de forma adaptativa la tasa de cada peso y acelera la fase inicial de aprendizaje en las capas recién inicializadas~\cite{kingma2015adam}.
        Su manejo robusto de gradientes ruidosos resulta pertinente ante bordes difusos y bajo contraste en los motivos~\cite{horn2022ai,jalandoni2022}.
        Además, converge más rápido que SGD cuando la anotación es limitada y heterogénea~\cite{goodfellow2016deep}. \\[0.3em]

        AdamW &
        Desacopla la descomposición de pesos de los momentos, ofreciendo una regularización más directa y reduciendo el sobreajuste en arquitecturas con capas normalizadas~\cite{loshchilov2019adamw}.
        Se ha utilizado con éxito en transformadores deformables para objetos pequeños y superpuestos~\cite{zhu2021,smallobjDETR}, lo que lo vuelve idóneo cuando el mismo modelo debe aprender simultáneamente motivos grandes y trazos finos presentes en paneles rupestres. \\
    \end{tabular}
    \caption{Criterios de selección de los optimizadores según la arquitectura y los desafíos específicos del arte rupestre.}
    \label{tab:optimizadores}
\end{table}


\subsection{Planificadores de Tasa de Aprendizaje}

Un \textbf{planificador de tasa de aprendizaje} (\emph{learning‐rate scheduler}) es un algoritmo que modifica la tasa de aprendizaje \(\eta\) a lo largo del entrenamiento según una regla predefinida—lineal, escalonada, cíclica, con reinicios, etc.—con el fin de acelerar la convergencia y mejorar la generalización~\cite{loshchilov2017,smith2019}.
Al reducir \(\eta\) cuando el gradiente se estabiliza o al aumentarla temporalmente para escapar de mesetas, el planificador actúa como un “ritmo cardíaco” que regula el tamaño de los pasos de optimización.

En este trabajo se utilizan seis planificadores que implementan estrategias complementarias frente a:
\renewcommand\labelenumi{(\alph{enumi})}
\begin{enumerate}
    \item \textbf{mesetas}, donde la pérdida deja de descender de forma sostenida;
    \item \textbf{reinicios periódicos}, que re‐exploran el espacio de parámetros tras llegar a un mínimo local;
    \item \textbf{fases de calentamiento} (\emph{warm‐up}), útiles al comenzar desde pesos aleatorios en la \emph{head}.
\end{enumerate}

La programación se aplica mediante \textbf{grupos de parámetros diferenciados}: la \emph{backbone} (parámetros preentrenados) evoluciona con una tasa de aprendizaje base menor y atenuada, mientras que la \emph{head} de detección, inicializada desde cero, sigue un programa más agresivo.
Esta distinción permite preservar el conocimiento general capturado en la \emph{backbone} y, simultáneamente, adaptar rápidamente la \emph{head} a motivos de arte rupestre con baja frecuencia o bajo contraste.

\subsection*{Método Step LR}
Reduce la tasa en saltos discretos por la cantidad de épocas seleccionadas por el usuario, factor que mitiga el sobreajuste tras la fase de convergencia inicial.
La simplicidad del esquema facilita la reproducción de experimentos y proporciona estabilidad cuando los gradientes se estabilizan~\cite{goyal2017}.

\subsection*{Método Multi Step LR}
La estrategia \texttt{MultiStepLR} aplica un \emph{decaimiento escalonado} de la tasa de aprendizaje: esta se mantiene constante hasta alcanzar una lista de épocas-hito predefinidas y, en cada una de ellas, se reduce abruptamente mediante un factor fijo.
Al elegir hitos en los primeros dos tercios del entrenamiento (p.\,ej., en el 30 \% y el 60 \%), se conservan pasos amplios para explorar el espacio de parámetros al inicio y se emplean pasos más pequeños para el ajuste fino posterior.
Esta programación demostró ser eficaz en modelos de referencia como ResNet, donde los autores reducen la tasa de aprendizaje en las épocas 30 y 60 al entrenar en ImageNet~\cite{he2016deep}.
Estudios recientes explican que este esquema ayuda a evitar oscilaciones alrededor de mínimos locales y mejora la generalización al combinar fases de exploración y explotación~\cite{you2019lrdecay}.
En nuestra implementación, cada grupo de parámetros utiliza hitos independientes, lo que permite un decaimiento más conservador en la \emph{backbone} preentrenada y uno más agresivo en la \emph{head} de detección, alineando la dinámica de optimización con las necesidades de cada componente.

\subsection*{Método Reduce LR on Plateau}
Monitorea la pérdida de validación y reduce la tasa solo cuando la métrica deja de mejorar durante el número de épocas que se indique.
Es apropiado cuando las curvas de aprendizaje presentan mesetas prolongadas causadas por clases minoritarias~\cite{hinton2012}.

\subsection*{Método Cosine Annealing LR}
El planificador \texttt{CosineAnnealingLR} reduce la tasa de aprendizaje siguiendo una curva cosenoidal suave hasta un valor mínimo cercano a cero.
Esta transición continua evita los saltos bruscos de otros esquemas escalonados y permite que, en las últimas épocas, el optimizador realice ajustes extremadamente finos.
Se ha comprobado que tal comportamiento favorece la convergencia en tareas donde es necesario refinar bordes o matices de bajo contraste, características que suelen afinarse recién en las fases finales del entrenamiento, al tiempo que mantiene la estabilidad numérica~\cite{loshchilov2017}.

\subsection*{Método Cosine Annealing Warm Restarts}
Introduce reinicios programados dependiendo de cada cuantas épocas se le indique.
Cada ciclo reestablece una tasa alta que favorece la exploración y reduce la probabilidad de quedar atrapado en mínimos locales originados por ruido de fondo~\cite{loshchilov2017}.

\subsection*{Método One Cycle LR}
Incrementa la tasa de forma rápida hasta un máximo y luego la reduce siguiendo una función cóncava, estrategia que acelera la convergencia inicial y promueve la generalización (\emph{super-convergence})~\cite{smith2019}.
Su dinamismo resulta ventajoso en entrenamientos cortos sobre miles de recortes.

\begin{table}[!h]
    \centering
    \begin{tabular}{p{3.8cm} p{10.4cm}}
        \hline
        \textbf{Planificador} & \textbf{Adecuación al arte rupestre} \\
        \hline
        StepLR / MultiStepLR &
        Fases con tasa fija prolongadas estabilizan la extracción de rasgos globales y los saltos discretos reducen el sobreajuste en etapas tardías~\cite{goyal2017,goodfellow2016deep}.
        Han sido empleados con éxito en detección de motivos rupestres donde los conjuntos presentan gran variación de escala y tamaño~\cite{suhaimi2023}. \\[0.3em]

        ReduceLRonPlateau &
        Ajusta la tasa de forma reactiva cuando la métrica se estanca, útil cuando las clases minoritarias empiezan a dominar la función de pérdida~\cite{goodfellow2016deep}.
        Esta estrategia ha mostrado mejoras en proyectos de identificación automática de arte rupestre con distribuciones altamente desequilibradas~\cite{horn2022ai}. \\[0.3em]

        CosineAnnealing (con o sin reinicios) &
        La disminución suave preserva detalles finos sin cambios bruscos en la convergencia~\cite{loshchilov2017}.
        Los reinicios periódicos facilitan escapar de mínimos locales causados por fondos muy texturizados, frecuentes en capturas de roca~\cite{sharp2024}. \\[0.3em]

        OneCycleLR &
        La fase inicial agresiva aprende rasgos prominentes en pocas épocas, seguida de un descenso gradual que refina bordes difusos manteniendo la generalización~\cite{smith2019}.
        Ha demostrado converger rápido en experimentos de detección rupestre con tiempo de cómputo limitado~\cite{suhaimi2023}. \\
    \end{tabular}
    \caption{Criterios de elección de planificadores de tasa de aprendizaje frente a los desafíos de detección en arte rupestre.}
    \label{tab:lr_schedulers}
\end{table}

\subsection{Diseño del Proceso Experimental}

El estudio se organiza en cinco fases secuenciales que permiten validar el código, elegir hiperparámetros, comparar técnicas de preprocesamiento y consolidar los mejores modelos antes de la evaluación arqueológica definitiva.

\subsection*{Fase 1 - Prueba inicial sobre un subconjunto reducido}

Se realiza un \emph{ajuste fino} (\emph{fine-tuning}) de cada una de las cuatro arquitecturas \emph{preentrenadas} empleando un subconjunto equivalente al 10\,\% del total de recortes.
Los experimentos se ejecutan de forma mixta: local y en Vertex AI sobre \texttt{n2-highmem-16} (\emph{CPU}) para controlar costos y depurar el flujo de trabajo.
La partición aleatoria queda:

\begin{table}[!h]
    \centering
    \begin{tabular}{l r r r}
        \hline
        \textbf{Clase} & \textbf{Entrenamiento} & \textbf{Validación} & \textbf{Prueba} \\
        \hline
        Animal & 3\,724 & 655 & 2\,265 \\
        Hand   & 1\,517 & 250 &   894 \\
        \hline
        \textbf{Total} & 5\,241 & 905 & 3\,159 \\
    \end{tabular}
    \caption{Distribución de instancias en el subconjunto piloto (\textbf{10\,\%} del corpus completo).}
    \label{tab:pilot_split}
\end{table}

\paragraph{Hiperparámetros de referencia.}
Para garantizar una comparación justa, todos los modelos se configuran para ejecutar un \textbf{número similar de pasos de optimización} (\(\approx 5\,100\)).
Un \emph{paso de optimización} se define como la operación en la que se realiza \emph{retro-propagación} y se actualizan los parámetros.
Si se emplea \textit{gradient accumulation}, varias mini-lotes pueden acumularse antes de dicho paso.
En cada arquitectura se ajustan \texttt{num\_epochs}, \texttt{batch\_size} y \texttt{grad\_accum\_steps} de modo que el \emph{lote efectivo} ()número de imágenes que contribuyen a un mismo gradiente) sea siempre \(16\) y la suma de pasos de optimización coincida dentro de un margen del 2\,\%.

\begin{center}
\begin{tabular}{lccc}
\hline
\textbf{Modelo} & \texttt{num\_epochs} & \texttt{batch\_size} & \texttt{grad\_accum\_steps} \\
\hline
Faster\,R--CNN   & 8  & 4  & 4  \\
RetinaNet        & 8  & 4  & 4  \\
Deformable\,DETR & 10 & 2  & 8  \\
YOLOv5\,(valores internos del \texttt{train.py}) & 30 & 16 & -- \\
\hline
\end{tabular}
\end{center}

\noindent\small
\textit{Nota.} Deformable~DETR necesita más pasos (\(\sim 7\,800\)) para estabilizar su mecanismo de atención, mientras que YOLOv5 fija el número de épocas desde su propio motor de entrenamiento.

\noindent
Bajo esta estrategia, cada iteración de acumulación procesa, por ejemplo, \(4 \times 4 = 16\) imágenes en Faster~R-CNN y RetinaNet, o \(2 \times 8 = 16\) en Deformable~DETR; posteriormente se ejecuta una única actualización de parámetros.
Aunque el número de \texttt{num\_epochs} varía (véase la tabla), el recuento de pasos de optimización y la presión de regularización (lote efectivo idéntico) se mantienen equiparados.
Así se evita que las diferencias de rendimiento provengan de una mayor exposición a los datos o de un régimen de actualización más frecuente, y se centra la evaluación en la capacidad intrínseca de cada arquitectura para ajustarse al dominio del arte rupestre.

Para hacer totalmente reproducible el piloto y aislar el efecto de la arquitectura, se fijaron explícitamente los hiperparámetros de optimización que más influyen en la convergencia (optimizador, tasas de aprendizaje, regularización y planificador de LR).  A continuación se resumen.

\begin{table}[!h]
\centering
\caption{Hiperparámetros de entrenamiento utilizados en el piloto}
\label{tab:pilot_hparams}
\begin{tabular}{lcccccc}
\hline
\textbf{Modelo} & Opt.\ & LR back & LR head & WD & Scheduler (T\textsubscript{max}) & Warm-up \\
\hline
Faster R-CNN         & SGD   & $4\times10^{-4}$ & $4.5\times10^{-3}$ & $1\times10^{-4}$ & CosAnneal (8)  & 1 época \\
RetinaNet            & SGD   & $1\times10^{-3}$ & $1\times10^{-2}$   & $1\times10^{-4}$ & CosAnneal (8)  & 1 época \\
Deformable DETR      & AdamW & $1\times10^{-5}$ & $2\times10^{-4}$   & $1\times10^{-4}$ & CosAnneal (10) & 2 épocas \\
YOLOv5\,(train.py)   & SGD   & $1\times10^{-3}$ & —                 & $5\times10^{-4}$ & CosAnneal (30) & 3 épocas \\
\hline
\end{tabular}
\end{table}

\noindent
Las tasas de aprendizaje diferenciadas para la \emph{backbone} y la \emph{head} optimizan la transferencia de conocimiento: una tasa menor en la \emph{backbone} preserva las características genéricas aprendidas en ImageNet, mientras que una tasa mayor en la \emph{head} (inicializada desde cero) acelera la adaptación a los motivos específicos del arte rupestre.
El \textit{weight decay} modera el sobreajuste en un conjunto pequeño, el planificador cosenoidal suaviza el descenso de LR dentro del límite de épocas impuesto por el presupuesto, manteniendo aprendizaje efectivo hasta el final.
AdamW se emplea en Deformable DETR porque su desacople de la regularización ha demostrado mejor sinergia con la normalización y los bloques de atención, mientras que las restantes CNN rinden de forma estable con SGD.

\paragraph{Aumentos en línea durante el entrenamiento.}
Para que la prueba inicial mida la \textit{capacidad intrínseca} de cada arquitectura y no la ventaja de un realce previo, los recortes se alimentan a las redes sin preprocesamiento global.
No obstante, se aplica \emph{aumento de datos en línea} (\textit{data augmentation}) (transformaciones aleatorias sobre cada imagen durante el entrenamiento) para regularizar el aprendizaje:

\begin{itemize}
    \item \textbf{Faster\,R--CNN, RetinaNet y Deformable\,DETR} utilizan una canalización basada en \texttt{Albumentations}:
    volteo horizontal, brillo–contraste aleatorio, CLAHE de bajo clip, traslación/escala (\(\pm 10\%\)), rotación a \(90^{\circ}\),
    y ajuste de tamaño máximo a \(1024\times1024\)~px, seguido de relleno para que las dimensiones resulten divisibles por 32.
    Las cajas se transforman automáticamente en formato \textit{Pascal VOC} (o \textit{YOLO} para DETR) y el tensor sale normalizado.
    \item \textbf{YOLOv5} mantiene su esquema interno.
    Sólo se activan las variaciones de tono-saturación-valor (\texttt{hsv\_h}=0.015, \texttt{hsv\_s}=0.70, \texttt{hsv\_v}=0.40) y se deshabilitan \texttt{mosaic}, \texttt{mixup} y \texttt{copy\_paste} (composición multicelda de recortes, mezcla lineal de pares de imágenes y pegado de objetos sintetizados, respectivamente) para mantener un régimen comparable.
\end{itemize}

Estas transformaciones \emph{no se consideran técnicas de preprocesamiento} porque:

\begin{enumerate}
    \item Se ejecutan \textbf{únicamente en tiempo de entrenamiento}.
    Los conjuntos de validación y prueba reciben las imágenes sin modificaciones, de modo que la métrica refleja el rendimiento genuino del modelo.
    \item No persisten sobre disco ni alteran el conjunto base.
    Actúan como regularización estocástica (igual que\textit{dropout}) y, por tanto, no compiten con los filtros de realce evaluados en la Fase 2.
    De hecho, cuando en la Fase 2 se aplica un preprocesamiento global (p.\,ej.\ CLAHE o Pirámide Laplaciana), los aumentos aquí descritos se mantienen de forma \textit{aditiva} para conservar la comparabilidad entre fases.
\end{enumerate}

Con este esquema cada iteración de la variable procesa un lote efectivo de 16 imágenes y totaliza, aproximadamente, \(5\,100\) pasos de optimización por modelo (véase la Tabla~\ref{tab:pilot_hparams}), lo que garantiza que las diferencias observadas se deban al diseño de la red y no a una exposición desigual a los datos.

La fase identifica tasas de aprendizaje, funciones de pérdida y planificadores estables para cada red.

\subsection*{Fase 2 - Aplicación sistemática de preprocesamiento}

Se repiten los entrenamientos con los hiperparámetros ya fijados, esta vez aplicando, de forma individual, cada una de las cuatro técnicas de realce descritas en la Sección~\ref{sec:preproc}.
Los trabajos se lanzan en Vertex AI sobre \texttt{n1-standard-4} con GPU Tesla T4 para reducir el tiempo por época y permitir pruebas exhaustivas.

\subsection*{Fase 3 - Análisis comparativo de resultados}

Se compilan tablas y gráficos que integran pérdida\_entrenamiento, pérdida\_validación, mAP\textsubscript{0.5} y mAR\textsubscript{100}.
El ranking resultante selecciona las tres combinaciones modelo + preprocesamiento con mejor equilibrio entre precisión y cobertura.

\subsection*{Fase 4 - Entrenamiento integral}

Las tres configuraciones destacadas se reentrenan durante veinte épocas sobre el \emph{total} de datos disponibles (\textbf{32\,538} recortes).
El objetivo es afinar pesos con mayor diversidad iconográfica y confirmar la estabilidad observada en las fases previas.

\subsection*{Fase 5 - Validación experta}

La arqueóloga especializada revisa, en sesiones conjuntas, las salidas de los modelos finales.
Se documentan aciertos y errores en la segmentación de motivos superpuestos, de bajo contraste o parcialmente erosionados.
Las observaciones cualitativas complementan las métricas cuantitativas y orientan ajustes futuros en la línea de investigación.

\section{Agrupamiento No Supervisado}
\label{sec:unsup}

En esta sección se implementan y analizan métodos de aprendizaje no supervisado para la agrupación de imágenes de arte rupestre.
El objetivo es identificar patrones y estructuras ocultas en los datos sin recurrir a etiquetas predefinidas.
Se emplean diferentes modelos de extracción de características y algoritmos de agrupamiento para evaluar su desempeño y seleccionar las combinaciones más efectivas.

\subsection{Modelos de Extracción de Características}

Los modelos empleados no se entrenan desde cero; se cargan con pesos preentrenados en ImageNet y luego se someten a un \textbf{ajuste fino ligero} (\emph{fine-tuning}).
Concretamente, se congela la mayor parte de la \emph{backbone} y sólo se actualizan los últimos bloques convolucionales y la capa densa final, utilizando una tasa de aprendizaje \(10\times\) menor que la del resto de la red.
Este procedimiento permite que los clasificadores conserven el conocimiento genérico adquirido en la base de datos original mientras adaptan sus representaciones a los motivos de arte rupestre presentes en nuestro conjunto.

\begin{itemize}
    \item \textbf{ResNet18}: Propuesto por He et al., ResNet introduce conexiones residuales que facilitan el entrenamiento de redes profundas al mitigar el problema del gradiente desvaneciente~\cite{he2016deep}.
    \item \textbf{VGG16}: Desarrollado por Simonyan y Zisserman, VGG16 se caracteriza por su arquitectura profunda y uniforme, utilizando convoluciones de \(3 \times 3\) para capturar características de alto nivel~\cite{simonyan2014very}.
    \item \textbf{DenseNet121}: Huang et al. presentan DenseNet, que conecta cada capa con todas las anteriores, promoviendo la reutilización de características y mejorando el flujo de información~\cite{huang2017densely}.
    \item \textbf{InceptionV3}: Szegedy et al. introducen InceptionV3, que utiliza módulos de \emph{inception} para capturar características a múltiples escalas, siendo eficaz en la representación de variaciones en tamaño y forma~\cite{szegedy2016rethinking}.
\end{itemize}

Esta diversidad arquitectónica permite evaluar cómo la extracción de rasgos, tras el \emph{fine-tuning}, influye en la calidad del agrupamiento de motivos rupestres.

\subsection{Algoritmos de Agrupamiento}

Se aplican cuatro algoritmos de agrupamiento para explorar diferentes enfoques en la agrupación de datos:

\begin{itemize}
    \item \textbf{K-Means}:
    Es un algoritmo de partición que asigna cada punto de datos al cluster más cercano en distancia euclídea, minimizando la suma de distancias al centroide~\cite{macqueen1967some}.
    Es eficiente en términos computacionales y funciona bien con clusters de forma esférica.
    \item \textbf{Clustering Aglomerativo}:
    Es un método jerárquico que fusiona iterativamente clusters basándose en una medida de similitud, capturando estructuras anidadas en los datos~\cite{rokach2005clustering}.
    No requiere especificar el número de clusters a priori y puede utilizar diferentes criterios de distancia entre grupos (simple, completo, promedio).
    \item \textbf{DBSCAN}:
    Identifica clusters de forma arbitraria y es robusto frente al ruido, agrupando puntos densamente conectados~\cite{ester1996density}.
    Es especialmente útil para detectar clusters de formas complejas y manejar datos con ruido.
    \item \textbf{Clustering Espectral}:
    Utiliza técnicas de álgebra lineal y teoría de grafos para identificar clusters en datos con estructuras complejas~\cite{ng2002spectral}.
    Es efectivo para detectar clusters que no son necesariamente convexos o separables linealmente.
\end{itemize}

La selección de estos algoritmos permite explorar diferentes metodologías de agrupamiento y evaluar cuál se adapta mejor a las características de los datos.

\subsection{Diseño del Proceso Experimental}\label{sec:unsup_design}

El análisis no supervisado se estructura en cinco etapas que permiten explorar la organización latente de los \(46\,348\) recortes de la clase \textit{Animal} y contrastar los resultados con la clasificación tipológica propuesta por la arqueología.

\subsubsection*{Fase 1 - Extracción automática de características}

Cada recorte se normaliza y se reescala a \(224\times224\,\text{px}\).
Posteriormente se generan vectores de activación con cuatro redes convolucionales preentrenadas en ImageNet (\emph{ResNet18}, \emph{ResNet50}, \emph{DenseNet121} y \emph{VGG16}) cuyos clasificadores finales se sustituyen por capas identidad.
El proceso produce, para cada imagen, un descriptor de entre 512 y 2\,048 dimensiones según la arquitectura.

\subsubsection*{Fase 2 - Reducción de dimensionalidad}

Con el fin de atenuar el ruido, acelerar los algoritmos de agrupamiento y facilitar la interpretación visual, los descriptores se proyectaron mediante\emph{Análisis de Componentes Principales} (PCA) conservando las primeras 50 componentes principales.
Esta proyección retiene aproximadamente el \textbf{80–85 \%} de la varianza total de los vectores de características, un umbral ampliamente recomendado que preserva la estructura de distancias al tiempo que reduce la dimensión en más de un 90 \%~\cite{jolliffe2016principal}.

\subsubsection*{Fase 3 - Agrupamiento cruzado}

Sobre la representación reducida se aplican cuatro estrategias: \emph{k}-means, agrupamiento jerárquico aglomerativo (\emph{ward}), clustering espectral y DBSCAN.
La combinación de las cuatro redes con los cuatro algoritmos origina 16 configuraciones.
Para los métodos que exigen \(k\) se exploran valores de \(2\) a \(10\). En DBSCAN se ajustan \(\varepsilon\) entre \(0.4\) y \(0.7\), con \textit{min samples} tomando un valor de 5.
Estos rangos cubren desde agrupamientos muy gruesos hasta un nivel de detalle ligeramente superior a las 6 categorías principales que usan los arqueólogos para clasificar manualmente los guanacos, de modo que podemos detectar si los motivos se descomponen en subgrupos significativos sin caer en el sobre-fraccionamiento o la mezcla excesiva de clases.

\subsubsection*{Fase 4 - Selección de configuraciones prometedoras}

Cada ejecución se evalúa con la puntuación de silueta media, el índice Davies–Bouldin y el criterio de Calinski–Harabasz~\citep{rousseeuw1987silhouettes,davies1979cluster,calinski1974dendrite}.
Se retienen las tres configuraciones cuyo promedio normalizado de estas métricas resulta máximo.
Adicionalmente, se examina la coherencia entre los conglomerados y las etiquetas zoomórficas originales (artiodáctilo, ave, piche, matuasto) mediante la homogeneidad y la completitud, lo que permite cuantificar la capacidad de los métodos no supervisados para recuperar conocimiento arqueológico existente.

\subsubsection*{Fase 5 - Validación experta}

Las agrupaciones seleccionadas se presentan a la especialista para una inspección cualitativa.
Se generan collages de 30 imágenes por clúster, lo que facilita la detección de patrones morfológicos consistentes o la identificación de mezclas indeseadas.
Las observaciones se contrastan con la nomenclatura tipológica vigente y se documentan discrepancias susceptibles de motivar nuevas hipótesis sobre variación estilística o cronológica.

Este flujo de trabajo, del descriptor convolucional al juicio experto, establece un puente entre el modelado de datos y el conocimiento disciplinar, y crea un marco replicable para futuras ampliaciones del corpus.

\newpage
